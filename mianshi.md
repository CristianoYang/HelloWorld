## 									根据简历反推面试题

https://www.jianshu.com/p/a07d1d4004b0

### 1. JAVA：

#### 1.1 容器：

1. Java常见容器介绍一下：

   **答**：主要三类List，Set，Map。区别：List是有序集合，可以重复；Set是散列表无序，不可用重复；Map是无序键值对，键不可以重复，值可以重复。（`HashMap`的键可以是null，`HashTable`的键不能为null）；

   List的实现可以分为`ArrayList`，`LinkedList`，`vector`。区别：`ArrayList`底层是数组，插入删除复杂度受元素位置影响，支持随机访问，线程不安全；`LinkedList`底层是双向链表，不支持随机访问，线程不安全；`vector`线程安全。

   Set的主要实现为`HashSet`，（无序，唯一）: 基于 `HashMap` 实现的，底层采用 `HashMap` 来保存元素

   Map的主要实现为`HashMap`，JDK1.8 之前 `HashMap` 由数组+链表组成的，数组是 `HashMap`  的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于  64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。

2. `ArrayList`的扩容机制？

   **答：** 以无参数构造方法创建ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。**ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右**

3. 比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同？

   **答：**`HashSet` 是 `Set` 接口的主要实现类 ，`HashSet` 的底层是 `HashMap`，线程不安全，可以存储 null 值；

   `LinkedHashSet` 是 `HashSet` 的子类，能够按照添加的顺序遍历；

   实际上LinkedHashMap的Entry数据结构会多两个属性：before和after，使得LinkedHashMap形成循环双链表，然后可以按照插入顺序或者LRU顺序进行读取；如果是LRU，把最近访问的移到队尾，头结点就是要删除的。

   `TreeSet` 底层使用红黑树，能够按照添加元素的顺序进行遍历，排序的方式有自然排序和定制排序。自定义排序就是重写Comparator的compare方法。

4. HashSet怎么检查重复？

   **答：**当你把对象加入`HashSet`时，`HashSet` 会先计算对象的`hashcode`值来判断对象加入的位置，同时也会与其他加入的对象的 `hashcode` 值作比较，如果没有相符的 `hashcode`，`HashSet` 会假设对象没有重复出现。但是如果发现有相同 `hashcode` 值的对象，这时会调用`equals()`方法来检查 `hashcode` 相等的对象是否真的相同。如果两者相同，`HashSet` 就不会让加入操作成功。

5. HashMap为什么线程不安全？ConcurrentHashMap线程安全底层怎么实现的？和HashTable的区别？

   **答：**HashMap在并发下的rehash会造成一些元素形成循环链表，导致死循环。

   JDK1.7中ConcurrentHashMap使用的是**分段数组+链表**，JDK1.8使用的是**数组+链表/红黑二叉树**，HashTable使用的是**数组+链表**；

   线程安全方法：ConcurrentHashMap在JDK1.7中使用分段锁（Segment），不同数据段不存在竞争提高并发。JDK1.8后不用Segment，使用Node数组，并发使用**`synchronized` 和 CAS 来操作**。HashTable使用同一把锁synchronized来保证安全，但是效率低下。
   
6. hashMap时间复杂度？

   - 理想情况下，hash不冲突，那读写就是o(1)
   - 如果冲突形成链表，那就是o(n)
   - 1.8后使用红黑树，就是o(logn)

7. hashMap底层为什么要使用数组？

   - hashMap定位桶的位置是利用元素的key的哈希值对数组长度取模得到，知道了桶的位置显然数组查找比LinkedList快
   - 可以自定义扩容机制

#### 1.2 并发

1. 什么是进程、线程和协程？

   **进程**是系统运行程序的基本单位，可以说是拥有资源的基本单位。在java中，启动main函数就是启动了一个JVM的进程，main函数所在线程就是主线程。

   **线程**是比进程更小的执行单位，可以说是CPU调度执行 的基本单位，一个进程可以包含多个线程。进程之间是独立的，互不影响，而线程有共享的内存区域，会相互影响。相比于进程，线程更加轻量级、执行开销小，但是不利于资源的管理和保护。

   **协程**是一种比线程更加轻量级的存在。一个线程可以拥有多个协程，不被操作系统内核管理，而是完全由用户控制。好处是性能得到提升，没有线程切换的开销大。（java原生语法没有实现协程）

2. 并发和并行的区别

   并发是指同一时间段，多个任务都在执行；

   并行是指单位时间内，多个任务同时执行。

3. 线程状态？

   NEW初始状态：线程创建完成，还没执行start（）方法；

   RUNNABLE运行状态：包括就绪和运行两种状态；

   BLOCKED阻塞状态：线程阻塞于锁；

   WAITING等待状态：当前线程需要等待其他线程做出特定动作，比如通知中断；

   TIME_WAITING超时等待：在指定时间自动返回；

   TERMINATED终止状态：当前线程执行完毕。

4. 多线程常用方法？

   start()：启动线程，调用run()方法，不能直接使用run方法，否则只是普通方法，不是多线程；

   run()：Thread类的run()方法与Runnable接口中的run()方法的功能和作用相同，都用来定义线程对象被调度之后所执行的操作，都是系统自动调用而用户程序不得引用的方法。

   sleep()：主要的作用是让当前线程停止执行，把cpu让给其他线程执行，但**不会释放对象锁和监控的状态**，到了指定时间后线程又会自动恢复运行状态。注意：线程睡眠到期自动苏醒，并返回到**可运行状态**，不是运行状态，不能保证该线程睡眠到期后就开始执行。

   wait()：**进入阻塞状态，释放锁**，接收notify或者notifyAll来唤醒，如果有时间参数，到时间也可以继续；

   yield()：进入就绪状态，释放cpu让给其他相同优先级线程，但是小概率会继续运行。

   join()：阻塞当前调用它的线程，等待join执行完毕，当前线程继续执行；

   interupt()：中断，由运行状态到死亡状态。中断线程操作实质上是修改了一下中断标示位为true，当前线程正在运行，仅仅修改标示位，不在做其他的事；当前线程正在阻塞，修改标识位，如果是join，sleep，yield，则会抛出Interrup异常，修改标示位为false。

5. 什么是死锁？怎么避免死锁？

   多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。

   学过操作系统的朋友都知道产生死锁必须具备以下四个条件：

   1. 互斥条件：该资源任意一个时刻只由一个线程占用。
   2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
   3. 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
   4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

   **避免死锁：**

   1. **破坏互斥条件** ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
   2. **破坏请求与保持条件**  ：一次性申请所有的资源。
   3. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
   4. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

6. synchronized关键字的了解？

   **`synchronized` 关键字解决的是多个线程之间访问资源的同步性，`synchronized`关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。**

   三种使用方式：

   1. **修饰实例方法**：作用于当前对象实例加锁，进入同步代码前要获得 **当前对象实例的锁**
   2. **修饰静态方法:** 也就是给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 **当前 class 的锁**。
   3. **修饰代码块** ：指定加锁对象，对给定对象/类加锁。`synchronized(this|object)` 表示进入同步代码库前要获得**给定对象的锁**。`synchronized(类.class)` 表示进入同步代码前要获得 **当前 class 的锁**

   synchronized底层原理：重量级锁是通过对象内部的一个叫做监视器锁（monitor）来实现的，监视器锁本质又是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的。而操作系统实现线程之间的切换需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。

7. synchronized锁升级？锁粗化？锁消除？

   锁的四种状态：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态

   1. 偏向锁：不存在锁竞争，常常是一个线程反复获取某个资源锁。设置偏向锁，在对象头和栈帧中记录锁的线程id。如果id一致，不用CAS进行加解锁。如果不一致，看看记录id的线程是否存活，不存活则置为无所状态，然后偏向新的线程；如果存活，看看是否需要继续持有资源，是的，则升级为轻量级锁，否则释放资源。
   2. 轻量级锁：竞争锁对象的线程不多，而且线程持有锁的时间也不长的情景。因为阻塞线程需要CPU从用户态转到内核态，代价较大，如果刚刚阻塞不久这个锁就被释放了，那这个代价就有点得不偿失了，因此这个时候就干脆不阻塞这个线程，让它自旋这等待锁释放。
   3. 重量级锁：如果自旋的时间太长也不行，因为自旋是要消耗CPU的，因此自旋的次数是有限制的，比如10次或者100次，如果自旋次数到了线程1还没有释放锁，或者线程1还在执行，线程2还在自旋等待，这时又有一个线程3过来竞争这个锁对象，那么这个时候轻量级锁就会膨胀为重量级锁。重量级锁把除了拥有锁的线程都阻塞，防止CPU空转。

   **锁粗化**就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁，避免频繁的加锁解锁操作。

   **锁消除：**通过对运行上下文的扫描，经过逃逸分析，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间。
   
8. synchronized和ReentrantLock的区别？

   二者都是可重入锁；synchronized依赖JVM，而ReentrantLock依赖API（JDK层面）；ReentrantLock提供了一些更加高级的功能，等待可中断、可实现公平锁、可实现选择性通知。

9. volatile作用？实现原理？ 

   **保持内存可见性**：所有线程都能看到共享内存的最新状态。原理：每次读取前必须先从主内存刷新最新的值，每次写入后必须立即同步回主内存当中。

   **防止指令重排**，通过`“内存屏障”`来防止指令被重排序。

10. TreadLocal是什么？原理详解？

     `ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。

    原理：每个`Thread`中都具备一个`ThreadLocalMap`，而`ThreadLocalMap`可以存储以`ThreadLocal`为 key ，Object 对象为 value 的键值对。

    ThreadLocalMap成员变量：

    - capacity：初始容量16，必须是2的幂，因为这样在计算下标的时候很方便
    - Entry[]数组，长度也是2的幂
    - size：entrys的个数，判断是否超过阈值需要进行扩容
    - threshold：阈值，总长度的2/3（和hashmap的负载因子不一样）

    Entry类：Entry继承弱引用，可以将ThreadLocal生命周期和线程生命周期解绑，可以避免线程得不到销毁而ThreadLocal无法回收。

    Set（）方法：

    - ThreadLocal的set（）方法，先获取当前线程，然后获取当前线程的map，如果map为null，则新建一个map，否则执行map的set（）方法
    - ThreadLocalMap的set（）方法很复杂，简单点来说：
      - 线性探测法解决hash冲突，因为Entry是没有next字段，也就不会形成链表，如果当前位置已经有元素，则往下寻找空位插入，类似一个循环数组
      - 整个空间都没有位置，会溢出
      - 往下探测的过程中，发现过期的key，会删除无效的entry，并进行替换

    Get（）方法：

    - ThreadLocal的get（）方法，获取当前线程，然后或者当前线程的map，如果为空，返回初始化initialValue（）值，然后创建新的map，否则执行map的getEntry（）方法
    - ThreadLocalMap的getEntry（）方法：
      - 根据hash值和table大小计算下标，如果下标处非空且刚好是key则返回，否则说明hash冲突，移到别的位置了
      - 直接计算下标找不到的时候，使用线性探测法查找，顺便清除无效的key

    过期数据指的就是ThreadLocal这个弱引用key被GC回收。

    扩容：当元素超过阈值，也就是长度的2/3，不会马上扩容，先进行过期数据清理，清理完数据仍大于长度的1/2，则进行扩容2倍。

11. 为什么要使用线程池？

    - **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
    - **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
    - **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控

13. TreadPoolExecutor重要参数？

    - **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
    - **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
    - **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

    ![图解线程池实现原理](D:\面试\面试题\img\图解线程池实现原理.png)

14. 线程池饱和策略？

    - **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
    - **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
    - **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。
    - **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。

14. 线程池源码级详解

    类结构：

    - Executor：最顶层接口，只包含一个executor（）方法
    - ExecutorService：继承Executor接口，添加了submit（）方法，并添加了线程池状态，比如shutdown（）等
    - AbstractExecutorService：继承ExecutorService，并实现了若干方法，如submit()等
    - ThreadPoolExecutor : 继承于AbstractExecutorService，是线程池的核心类，几乎所有与线程池有关的逻辑都封装在这个类里边。
    - DiscardPolicy、DiscardOldestPolicy、AbortPolicy、CallerRunsPolicy : 四种饱和策略。
    - Worker : 线程池真正的线程类，本身实现了Runnable接口和AQS(AbstractQueuedSynchronizer)接口。

    线程池的状态：

    - running： 运行态，也是线程池的默认状态，当new一个ThreadPoolExecutor实例之后，这个ThreadPoolExecutor的状态就是运行态。运行态能够接受新添加任务，也能够对阻塞队列中的任务进行处理。
    - shutdown：关闭态，当调用ThreadPoolExecutor实例的showdown()方法之后，这个ThreadPoolExecutor实例就会进入关闭态。关闭态能够对阻塞队列中的任务进行处理，不能够接受新添加的非空任务，但是可以接受新添加的空任务。
    - stop：停止态，当调用ThreadPoolExecutor实例的shutdownNow()方法之后，这个ThreadPoolExecutor实例就会进入停止态。停止态不能接受新添加任务，也不能够对阻塞队列中的任务进行处理，并且会中断正在运行的任务。
    - tidying： 整理态，当线程池中所有任务已被终止， 这个ThreadPoolExecutor实例就会进入停止态。
    - terminated：结束态，当线程池处于整理态，并调用terminated()方法，执行完毕之后，就会进入结束态，此状态也表示整个线程池生命周期的结束。

    线程池的工作流程：

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210219131549320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L211X3dpbmQ=,size_16,color_FFFFFF,t_70#pic_center)

    ​	需要补充的是，Worker类里面有自己的线程，执行完一个任务会循环去找下一个任务getTask()！

    submit和executor的区别：

    - execute只能提交Runnable类型的任务，而submit既能提交Runnable类型任务也能提交Callable类型任务。
    - execute会直接抛出任务执行时的异常，submit会吃掉异常，可通过Future的get方法将任务执行时的异常重新抛出。
    - execute没有返回值，submit有返回值，所以需要返回值的时候必须使用submit
    - 实际上submit里面也是执行的executor。

15. 请你说一下自己对于 AQS 原理的理解？

    AQS就是一个并发包的基础组件，用来实现各种锁，各种同步组件的。

    它包含了state变量、加锁线程、等待队列等并发中的核心组件。

    ![img](D:\面试\面试题\img\AQS.png)

16. 解释一下 CountDownLatch 概念？给出一些 CountDownLatch 使用的例子？不足之处？

    CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程执行完后再执行。`CountDownLatch` 是共享锁的一种实现,它默认构造 AQS 的 `state` 值为 `count`。

    两种用法：

    - 某一线程在开始运行前等待 n 个线程执行完毕。将 CountDownLatch 的计数器初始化为 n ：`new CountDownLatch(n)`，每当一个任务线程执行完毕，就将计数器减 1 `countdownlatch.countDown()`，当计数器的值变为 0 时，在`CountDownLatch上 await()` 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。
    - 实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 `CountDownLatch` 对象，将其计数器初始化为 1 ：`new CountDownLatch(1)`，多个线程在开始执行任务前首先 `coundownlatch.await()`，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。

    不足之处：CountDownLatch 是**一次性的**，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。

17. CyclicBarrier的概念？原理？

    CyclicBarrier也叫同步屏障、或者循环栅栏，允许让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。

    现实生活中我们经常会遇到这样的情景，在进行某个活动前需要等待人全部都齐了才开始。例如吃饭时要等全家人都上座了才动筷子，旅游时要等全部人都到齐了才出发，比赛时要等运动员都上场后才开始。

    原理：在CyclicBarrier类的内部有一个计数器，每个线程在到达屏障点的时候都会调用await方法将自己阻塞，此时计数器会减1，当计数器减为0的时候所有因调用await方法而被阻塞的线程将被唤醒。

18. 上面两者的区别？

    CountDownLatch 是计数器，只能使用一次，而 CyclicBarrier 的计数器提供 reset 功能，可以多次使用。对于 CountDownLatch 来说，重点是“一个线程（多个线程）等待”，而其他的 N 个线程在完成“某件事情”之后，可以终止，也可以等待。而对于 CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。

19. 什么是乐观锁（CAS）？存在什么缺点？

    CAS,compare and swap的缩写，中文翻译成比较并交换。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。

    缺点：

    - 存在ABA问题：因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。可以通过增加标志位来解决。
    - 循环时间长开销大：自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。
    - 只能保证一个共享变量的原子操作。

20. 自旋锁代码？

    ```java
    class SpinLock {
        private AtomicReference<Thread> cas = new AtomicReference<Thread>();
        public void lock() {
            Thread current = Thread.currentThread();
            while(!cas.compareAndSet(null, current)) {
                //Do Nothing
            }
        }
        public void unlock() {
            Thread current = Thread.currentThread();
            cas.compareAndSet(current, null);
        }
    }
    ```

21. i++是否线程安全？

    不安全，因为i++其实是分为三步，第一步读取i值，第二步加1，第三步赋值给i。这三步任意之间都有可能会由cpu调度造成i值修改。

    如果是方法里面定义的，是安全的，因为方法是线程私有；如果是静态变量，则线程不安全。

    可以通过synchronized进行同步；或者使用cas的原子类。

22. 创建多线程的方法？

    （1）继承Thread类，重写run方法

    ```java
    public class Main{
    	public static void main(String[] args){
            new MyThread().start();
        }
    }
    
    class MyThread extends Thread{
        @Override
        public void run(){
            System.out.println(Thread.currentThread.getName());
        }
    }
    ```

    （2）实现Runnable接口，重写run方法，用Thread类包装

    ```java
    public class Main {
        public static void main(String[] args){
            MyThread thread = new MyThread();
            new Thread(thread).start();
        }
    }
    
    class MyThread implements Runnable{
        @Override
        public void run(){
            System.out.println(Thread.currentThread.getName());
        }
    }
    ```

    （3）实现Callable，重写call方法，用FutureTask类包装，再用Thread类包装

    ```java
    public class Main{
        public static void main(String[] args){
            // 将Callable包装成FutureTask，FutureTask也是一种Runnable
            MyCallable callable = new MyCallable();
            FutureTask<Integer> futureTask = new FutureTask<>(callable);
            new Thread(futureTask).start();
    
            // get方法会阻塞调用的线程
            Integer sum = futureTask.get();
            System.out.println(Thread.currentThread().getName() + Thread.currentThread().getId() + "=" + sum);
        }
    }
    
    class MyCallable implements Callable<Integer>{
        @Override
        public Integer call() throws Exception{
            System.out.println(Thread.currentThread.getName());
            int sum = 0;
            for (int i = 0; i <= 100000; i++) {
                sum += i;
            }
            Thread.sleep(5000);
            System.out.println(Thread.currentThread.getName());
            return sum;
        }
    }
    ```

    （4）三者的区别？

    - Thread: 继承方式, 不建议使用, 因为Java是单继承的，继承了Thread就没办法继承其它类了，不够灵活
    - Runnable: 实现接口，比Thread类更加灵活，没有单继承的限制
    - Callable: Thread和Runnable都是重写的run()方法并且没有返回值，Callable是重写的call()方法并且有返回值并可以借助FutureTask类来判断线程是否已经执行完毕或者取消线程执行
    - 当线程不需要返回值时使用Runnable，需要返回值时就使用Callable，一般情况下不直接把线程体代码放到Thread类中，一般通过Thread类来启动线程
      Thread类是实现Runnable，Callable封装成FutureTask，FutureTask实现RunnableFuture，RunnableFuture继承Runnable，所以Callable也算是一种Runnable，所以三种实现方式本质上都是Runnable实现

23. FutureTask详解

    FutureTask实现了RunnableFuture接口，而RunnableFuture继承了Runnable和Future，也就是说FutureTask既是Runnable，也是Future。

    核心成员：

    - volatile int state：表示对象状态，定义了7种状态

      ```java
      private static final int NEW          = 0; //任务新建和执行中
      private static final int COMPLETING   = 1; //任务将要执行完毕
      private static final int NORMAL       = 2; //任务正常执行结束
      private static final int EXCEPTIONAL  = 3; //任务异常
      private static final int CANCELLED    = 4; //任务取消
      private static final int INTERRUPTING = 5; //任务线程即将被中断
      private static final int INTERRUPTED  = 6; //任务线程已中断
      ```

    - Callable<V> callable：被提交的任务

    - Object outcome：任务执行结果或者任务异常

    - volatile Thread runner:执行任务的线程

    - volatile WaitNode waiters：等待节点，关联等待线程

    内部状态转换：

    ​	FutureTask使用state来表示当前状态，state的值变更由CAS表示原子性。一般来说有以下四种情况：

    - 任务正常执行并返回。 NEW -> COMPLETING -> NORMAL
    - 执行中出现异常。NEW -> COMPLETING -> EXCEPTIONAL
    - 任务执行过程中被取消，并且不响应中断。NEW -> CANCELLED
    - 任务执行过程中被取消，并且响应中断。 NEW -> INTERRUPTING -> INTERRUPTED

    核心方法：

    - run（）

      1. 校验当前任务状态是否为NEW以及runner是否已赋值。这一步是防止任务被取消。
      2. double-check任务状态state
      3. 执行业务逻辑，也就是c.call()方法被执行
      4. 如果业务逻辑异常，则调用setException方法将异常对象赋给outcome，并且更新state值
      5. 如果业务正常，则调用set方法将执行结果赋给outcome，并且更新state值

    - set（V， v）

      状态变更的原子性由unsafe对象提供的CAS操作保证。FutureTask的outcome变量存储执行结果或者异常对象，会由主线程返回。

    - get()

      任务由线程池提供的线程执行，那么这时候主线程则会阻塞，直到任务线程唤醒它们。

      get原理就是首先校验参数，然后根据state状态判断是否超时，超时了就报异常，已经完成或者异常结束了就去report（）返回最终结果；

      如果任务还在进行中，那就进入awaitDone()函数

    - awaitDone（）

      1. 计算deadline，也就是到某个时间点后如果还没有返回结果，那么就超时了。
      2. 进入自旋，也就是死循环。
      3. 首先判断是否响应线程中断。对于线程中断的响应往往会放在线程进入阻塞之前，这里也印证了这一点。
      4. 判断state值，如果>COMPLETING表明任务已经取消或者已经执行完毕，就可以直接返回了。
      5. 如果任务还在执行，则为当前线程初始化一个等待节点WaitNode，入等待队列。这里和AQS的等待队列类似，只不过Node只关联线程，而没有状态。AQS里面的等待节点是有状态的。
      6. 计算nanos，判断是否已经超时。如果已经超时，则移除所有等待节点，直接返回state。超时的话，state的值仍然还是COMPLETING。
      7. 如果还未超时，就通过LockSupprot类提供的方法在指定时间内挂起当前线程，等待任务线程唤醒或者超时唤醒。

    - finishCompletion（）

      当任务正常结束或者异常时，都会调用finishCompletion去唤醒等待线程。这个时候，等待线程就可以醒来，开开心心的获得结果啦。

24. JUC包里都有哪些东西？

    - atomic原子类，核心是CAS
    - locks包，reentrantLock（可重入锁）、读写锁（ReadWriteLock）等。核心是AQS抽象队列同步器框架。
    - 并发容器：concurrentMap、BlockingQueue等
    - 执行框架线程池executor
    - 并发工具类：CountdownLatch、cyclicBarrier等

#### 1.3 JVM

1. JVM内存分区?

   ![img](D:\面试\面试题\img\Java内存分区JDK1.8.png)

   线程私有：虚拟机栈、本地方法栈、程序计数器。

   线程共享：堆、方法区，直接内存

2. 程序计数器的作用：

   - 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。

   - 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

3. Java对象的创建过程？

   ![Java创建对象的过程](D:\面试\面试题\img\Java创建对象的过程.png)

   - 类加载检查：虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。
   - 分配内存：
     - 指针碰撞：如果java中内存分配是规整的，那么指针就是分界线，给变量分配内存的过程就是指针挪动一个变量的大小
     - 空闲列表：如果java中内存分配不是规整的，那么虚拟机会维护一个空闲列表，用来记录可用内存。

4. 对象的访问定位：

   **句柄：** 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；  

   ![对象的访问定位-使用句柄](D:\面试\面试题\img\对象的访问定位-使用句柄.png)

   **直接指针：**  如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。

   ![对象的访问定位-直接指针](D:\面试\面试题\img\对象的访问定位-直接指针.png)

   **使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。**

5. 运行时常量池？

   常量池表用于存放编译期生成的各种字面量和符号引用；双引号创建的字符串直接在常量池中；基本类型的包装类也有常量池。

6. 垃圾回收机制？

   堆的分代：

   ![img](D:\面试\面试题\img\01d330d8-2710-4fad-a91c-7bbbfaaefc0e.png)

   - 对象优先在Eden区分配

   - 大对象直接进老年代

   - 长期存活的对象进入老年代

   - gc分类：

     部分收集 (Partial GC)：

     - 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；
     - 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；
     - 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。

     整堆收集 (Full GC)：收集整个 Java 堆和方法区。

   判断对象死亡：

   - 引用计数法：缺点是对象可能互相引用
   - 可达性分析：通过一系列的称为 **“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。

   四种引用：

   - 强引用：如果一个对象具有强引用，那就类似于**必不可少的生活用品**，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。
   
   - 软引用：如果一个对象只具有软引用，那就类似于**可有可无的生活用品**。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。
   
- 弱引用：如果一个对象只具有弱引用，那就类似于**可有可无的生活用品**。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。
   
- 虚引用：如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。
   
     虚引用必须和引用队列一起使用，程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。
   
   怎么判断无用的类：同时满足下面三个条件
   
   - 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
   - 加载该类的 `ClassLoader` 已经被回收。
   - 该类对应的 `java.lang.Class` 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。
   
7. 垃圾收集算法？

   - 标记-清除算法：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。此算法效率不高、内存不连续。
   - 复制算法：为了解决效率问题，它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。
   - 标记-整理算法：标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。
   - 分代收集算法：根据各个年代的特点选择合适的垃圾收集算法。

8. 常用垃圾收集器？CMS？G1？

   ![垃圾收集器分类](D:\面试\面试题\img\垃圾收集器.png)

   CMS：**是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作，**是一种 **“标记-清除”算法**实现的。主要优点：**并发收集、低停顿**。缺点会产生大量碎片内存。

   G1：**是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.**

9. 类加载机制？

   ![img](D:\面试\面试题\img\类加载过程.png)

   - 加载：完成下面三件事

     1. 通过全类名获取定义此类的二进制字节流
     2. 将字节流所代表的静态存储结构转换为方法区的运行时数据结构
     3. 在内存中生成一个代表该类的 Class 对象,作为方法区这些数据的访问入口

   - 验证：

     ![验证阶段示意图](D:\面试\面试题\img\验证阶段.png)

   - 准备：

     **准备阶段是正式为类变量分配内存并设置类变量初始值的阶段**，这些内存都将在方法区中分配。

     这时候进行内存分配的仅包括类变量（static），如果final修饰静态变量，可以直接赋值，否则是零值。

   - 解析：

     解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。

   - 初始化：

     初始化阶段是执行初始化方法 `<clinit> ()`方法的过程。这里是给所有静态变量赋值，前面准备的初始化是赋零值。

10. 类加载器？双亲委派模型？为什么要破坏双亲委派模型？

    类加载器：

    1.  **BootstrapClassLoader(启动类加载器)** ：最顶层的加载类，由C++实现，负责加载 `%JAVA_HOME%/lib`目录下的jar包和类或者或被 `-Xbootclasspath`参数指定的路径中的所有类。
    2. **ExtensionClassLoader(扩展类加载器)** ：主要负责加载目录 `%JRE_HOME%/lib/ext` 目录下的jar包和类，或被 `java.ext.dirs` 系统变量所指定的路径下的jar包。
    3. **AppClassLoader(应用程序类加载器)** :面向我们用户的加载器，负责加载当前应用classpath下的所有jar包和类。

    双亲委派模型：

    如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。

    双亲委派模型保证了Java程序的稳定运行，可以避免类的重复加载。
    
    **为什么破坏双亲委派：**
    
    在SPI（Service Provider Inteface）中实现破坏双亲委派。
    
    以Driver为例，JDK在lib中定义了数据库连接的规范接口，Driver由启动类加载器加载，实现类由各个厂家进行实现。但是厂家的实现总不能放进JDK库中吧，如果使用双亲委派模型，java就会由启动器类去找Driver，只能找到接口，就会报错！
    
    SPI Serviceloader 通过线程上下文获取能够加载实现类的classloader，一般情况下是 application classloader，绕过了这层限制，逻辑上打破了双亲委派原则。
    
    **自定义加载器：**
    
    需要继承 `ClassLoader` 。如果我们不想打破双亲委派模型，就重写 `ClassLoader` 类中的 `findClass()` 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 `loadClass()` 方法
    
11. JVM调优

    

#### 1.4 反射

JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 java 语言的反射机制。

获取class的四种方式;

1. 知道具体类，直接`.class`
2. 不知道具体类，通过`class.forName()`传入类的路径
3. 通过对象实例`instance.getClass()`获取
4. 通过类加载器`xxxClassLoader.loadClass()`传入类路径获取

反射机制的优缺点：

- **优点：** 运行期类型的判断，动态加载类，提高代码灵活度。
- **缺点：** 1,性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的 java 代码要慢很多。2,安全问题，让我们可以动态操作改变类的属性同时也增加了类的安全隐患。

应用场景：

- 我们在使用 JDBC 连接数据库时使用 `Class.forName()`通过反射加载数据库的驱动程序；

- Spring 框架的 IOC（动态加载管理 Bean）创建对象以及 AOP（动态代理）功能都和反射有联系；

- 动态配置实例的属性；

#### 1.5 代理模式

**使用代理对象来代替对真实对象(real object)的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。**

1. 静态代理：

   **静态代理中，我们对目标对象的每个方法的增强都是手动完成的**

   静态代理实现步骤:

   1. 定义一个接口及其实现类；
   2. 创建一个代理类同样实现这个接口
   3. 将目标对象注入进代理类，然后在代理类的对应方法调用目标类中的对应方法。这样的话，我们就可以通过代理类屏蔽对目标对象的访问，并且可以在目标方法执行前后做一些自己想做的事情。

2. 动态代理：

   相比于静态代理来说，动态代理更加灵活。我们不需要针对每个目标类都单独创建一个代理类，并且也不需要我们必须实现接口，我们可以直接代理实现类( *CGLIB 动态代理机制*)。

   - JDK动态代理：

     JDK 动态代理类使用步骤

     1. 定义一个接口及其实现类；
     2. 自定义 `InvocationHandler` 并重写`invoke`方法，在 `invoke` 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑；
     3. 通过 `Proxy.newProxyInstance(ClassLoader loader,Class<?>[] interfaces,InvocationHandler h)` 方法创建代理对象；

   - CGLIB 动态代理机制：不需要实现接口

     1. 定义一个类；
     2. 自定义 `MethodInterceptor` 并重写 `intercept` 方法，`intercept` 用于拦截增强被代理类的方法，和 JDK 动态代理中的 `invoke` 方法类似；
     3. 通过 `Enhancer` 类的 `create()`创建代理类；

#### 1.6 基础

1. static关键字？

   - static修饰成员变量和成员方法，被修饰的成员属于这个类，不属于某个对象，被类中所有对象共享，可以通过类名调用。静态变量成员存放在方法区中。
   - 静态代码块：无论类被实例化多少次，代码块只执行一次。
   - 静态内部类：它的创建不需要依赖外围类的创建；不能使用任何外围类的非静态成员变量和方法。

2. java8新特性？

   - lambda表达式

     ```java
     Collections.sort(names, (String a, String b) -> b.compareTo(a));
     ```

   - Stream流

     常用filter、sorted、map、match、count等

     ```java
     // 测试 Map 操作
             stringList
                     .stream()
                     .map(String::toUpperCase)
                     .sorted((a, b) -> b.compareTo(a))
                     .forEach(System.out::println);// "DDD2", "DDD1", "CCC", "BBB3", "BBB2", "AAA2", "AAA1"
     ```

   - Optional类检查空指针

   - 时间API，Clock、LocalDateTime，ZonedDateTime等

   - JDK8提供了接口static和Default方法。特别是Default修饰的方法，dafault修饰符是我们设计模式中的适配器设计模式的重要实现原理，让我们接口实现类不需要重写全部的抽象方法，default修饰的方法可以选择性的重写。

3. 抽象类和接口的区别？

   （1）抽象类

   - 抽象方法只有方法名，没有方法体，用abstract修饰
   - 抽象类用abstract修饰
   - 抽象类的构造器不能创造实例，不能实例化
   - 抽象类包含成员变量、方法（普通方法或者抽象方法都行）、初始化块、内部类
   - 抽象类不一定包含抽象方法，有抽象方法一定是抽象类
   - abstract和static不能修饰同一个方法，与private和final不能共存

   （2）接口

   - 接口方法都是公有的，编译时自动加上public、abstract
   - 接口里的成员变量只能是public、static、final共同修饰

   （3）区别

   - 接口里不能实现方法体，抽象类可以
   - 接口可以多继承，抽象类不行
   - 接口是被实现，抽象类是被继承
   - 接口中只能有公有方法和属性且必须赋初值，抽象类中可以有私有方法和属性
   - 接口中方法不能为static，属性可以，抽象类中方法可以静态，属性也可以
   
4. 红黑树基础了解？

   红黑树是一种近似平衡的二叉查找树，他并非绝对平衡，但是可以保证任何一个节点的左右子树的高度差不会超过二者中较低的那个的一倍。

   红黑树有这样的特点：

   - 每个节点要么是红色，要么是黑色。
   - 根节点必须是黑色。叶子节点必须是黑色NULL节点。
   - 红色节点不能连续。
   - 对于每个节点，从该点至叶子节点的任何路径，都含有相同个数的黑色节点。
   - 能够以O(log2(N))的时间复杂度进行搜索、插入、删除操作。此外,任何不平衡都会在3次旋转之内解决。

5. 什么是闭包？闭包的作用？闭包的缺点？

   **闭包**是指可以包含自由（未绑定到特定对象）变量的代码块；这些变量不是在这个代码块内或者任何全局上下文中定义的，而是在定义代码块的环境中定义（局部变量）。Java中通过接口和内部类来实现。

   作用：

   - 闭包的价值在于可以作为函数对象或者匿名函数，持有上下文数据，作为第一级对象进行传递和保存。
   - 闭包广泛用于回调函数、函数式编程中。

   缺点：

   - 由于闭包会使得函数中的变量都被保存在内存中，内存消耗很大。
   - 闭包会在父函数外部，改变父函数内部变量的值。

6. 浅拷贝和深拷贝？

   浅拷贝：

   ①对于数据类型是基本数据类型的成员变量，浅拷贝会直接进行值传递，也就是将该属性值复制一份给新的对象。因为是两份不同的数据，所以对其中一个对象的该成员变量值进行修改，不会影响另一个对象拷贝得到的数据。②对于数据类型是引用数据类型的成员变量，比如说成员变量是某个数组、某个类的对象等，那么浅拷贝会进行引用传递，也就是只是将该成员变量的引用值（内存地址）复制一份给新的对象。因为实际上两个对象的该成员变量都指向同一个实例。在这种情况下，在一个对象中修改该成员变量会影响到另一个对象的该成员变量值。

   深拷贝：

   对于深拷贝来说，不仅要复制对象的所有基本数据类型的成员变量值，还要为所有引用数据类型的成员变量申请存储空间，并复制每个引用数据类型成员变量所引用的对象，直到该对象可达的所有对象。也就是说，对象进行深拷贝要对整个对象图进行拷贝！

7. Java注解原理？

   **注解的本质就是一个继承了 Annotation 接口的接口。**

   解析一个类或者方法的注解往往有两种形式，一种是编译期直接的扫描，一种是运行期反射。

   『元注解』是用于修饰注解的注解，通常用在注解的定义上：

   - @Target：注解的作用目标
   - @Retention：注解的生命周期
   - @Documented：注解是否应当被包含在 JavaDoc 文档中
   - @Inherited：是否允许子类继承该注解

   内置注解：

   - @Override
   - @Deprecated
   - @SuppressWarnings

   自定义注解通常由反射和代理实现。

   当你进行反射的时候，虚拟机将所有生命周期在 RUNTIME 的注解取出来放到一个 map 中，并创建一个 AnnotationInvocationHandler 实例，把这个 map 传递给它。

   最后，虚拟机将采用 JDK 动态代理机制生成一个目标注解的代理类，并初始化好处理器。

8. Java泛型原理？

   泛型的本质是对类型进行参数化，在代码逻辑不关注具体的数据类型时使用。包括泛型方法、泛型类和泛型接口。
   
   **基本原理**：
   
   泛型本质是将数据类型参数化，它通过擦除的方式来实现。声明了泛型的 .java 源代码，在编译生成 .class  文件之后，泛型相关的信息就消失了。可以认为，源代码中泛型相关的信息，就是提供给编译器用的。泛型信息对 Java 编译器可以见，对 Java  虚拟机不可见。
   
   Java 编译器通过如下方式实现擦除：
   
   - 用 Object 或者界定类型替代泛型，产生的字节码中只包含了原始的类，接口和方法；
   - 在恰当的位置插入强制转换代码来确保类型安全；
   - 在继承了泛型类或接口的类中插入桥接方法来保留多态性。

### 2. 数据库

#### 2.1 Mysql

1. myisam和innodb的区别？

   - innodb支持事务，myisam不支持；

   - InnoDB支持外键，而MyISAM不支持；

   -  InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。

      MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。

     也就是说：InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。

   - InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁；

     InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁。

   - InnoDB表必须有唯一索引（如主键）（用户没有指定的话会自己找/生产一个隐藏列Row_id来充当默认主键），而Myisam可以没有；

   - Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI

     ​    Innodb：frm是表定义文件，ibd是数据文件

     ​    Myisam：frm是表定义文件，myd是数据文件，myi是索引文件

2. 索引底层原理？

   索引（Index）是帮助MySQL高效获取数据的数据结构。

   常见的索引结构有B-树、B+树、哈希索引。

   索引优缺点：

   - 优点：**可以大大加快 数据的检索速度（大大减少的检索的数据量）, 这也是创建索引的最主要的原因。毕竟大部分系统的读请求总是大于写请求的。** 另外，通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
   - 缺点：**创建索引和维护索引需要耗费许多时间**：当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。**占用物理存储空间** ：索引需要使用物理文件存储，也会耗费一定空间。

   B树和B+树的区别：

   - B树的所有节点既存放键也存放值；B+树只有叶子节点存放key和data，其余节点只存放key
   - B树的叶子节点都是独立的；B+树叶子节点有一个指针指向相邻叶子节点，形成了链表
   - B树二分查找，可能没到叶子节点检索就结束了；B+树任何查找都是从根节点到叶节点，效率稳定。

   哈希索引和B+树的区别：

   - 哈希索引适合等值查询，但是无法进行范围查询 
   - 哈希索引没办法利用索引完成排序 
   - 哈希索引不支持多列联合索引的最左匹配规则 
   - 如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题

3. myisam和innodb索引实现？

   myisam：

   - 使用的是B+树索引，叶节点的data存放的是数据记录的地址，属于非聚集索引。
   - 二级索引和主索引一样的结构，叶子节点data也是存放数据记录的地址。
   - 根据myi查询的地址从myd文件中得到数据

   innodb：

   - 使用的B+树索引，叶子节点的data域存放完整数据记录。
   - 主键索引属于聚集索引，优点：查询速度快，因为找到定位就得到了数据；缺点：依赖有序数据，如果无序插入就需要排序，效率慢，所有自增最好；另外更新代价大。
   - 二级索引属于非聚集索引，叶子节点只存放主键的值。优点是更新代价小，缺点是需要根据查询到的主键值进行回表操作，就是再去主键索引中根据主键查找数据。
   - 非聚集索引不一定非要回表，如果是覆盖索引就不用回表。

   覆盖索引：如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。

4. 联合索引和最左匹配原则？

   联合索引其实很简单，相对于一般索引只有一个字段，联合索引可以为多个字段创建一个索引。

   最左匹配原则：最左优先，以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(>、<、between、like)就会停止匹配。顺序无关，mysql会自动优化查询顺序。

   索引下推：当使用索引条件下推优化时，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器。索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。

5. 索引优化策略？

   - 最左前缀匹配原则
   - 对 where,on,group by,order by 中出现的列使用索引
   - 尽量选择区分度高的列作为索引
   - 为较长的字符串使用前缀索引
   - 尽量的扩展索引，不要新建索引。
   - 对于like查询，”%”不要放在前面。 
   - 查询where条件数据类型不匹配也无法使用索引 

6. 一条SQL语句在MySQL中如何执行的？

   - MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。
   - 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。
   - SQL 等执行过程分为两类，一类对于查询等过程如下：权限校验---》查询缓存---》分析器---》优化器---》权限校验---》执行器---》引擎
   - 对于更新等语句执行流程如下：分析器----》权限校验----》执行器---》引擎---redo log prepare---》binlog---》redo log commit

7. 一条SQL语句执行得很慢的原因有哪些？

   1、大多数情况下很正常，偶尔很慢，则有如下原因

   (1)、数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。

   (2)、执行的时候，遇到锁，如表锁、行锁。

   2、这条 SQL 语句一直执行的很慢，则有如下原因。

   (1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。

   (2)、数据库选错了索引。

8. 大表优化？

   - 限定数据的范围。查询语句必须带范围

   - 读/写分离，主库负责写，从库负责读

   - 垂直分区：数据表列的拆分，把一张列比较多的表拆分为多张表

     优点：可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。

     缺点：主键会出现冗余，需要管理冗余列

   - 水平分区：保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。

   - 数据库分片的两种常见方案：

     - **客户端代理：**  **分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。** 当当网的 **Sharding-JDBC** 、阿里的TDDL是两种比较常用的实现。
     - **中间件代理：** **在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。** 我们现在谈的 **Mycat** 、360的Atlas、网易的DDB等等都是这种架构的实现。

9. 介绍一下事务？

   事务四大特性：

   - **原子性：** 事务是最小的执行单位，不允许分割。
   - **一致性：** 执行事务前后，数据保持一致。
   - **隔离性：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
   - **持久性：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

   并发事务带来的问题

   - **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。

   - **丢失修改（Lost to modify）:**  指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。     例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。

   - **不可重复读（Unrepeatableread）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。

   - **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

     不可重复读的重点是修改，幻读的重点在于新增或者删除。

   事务隔离级别：

   | 隔离级别                         | 脏读 | 不可重复读 | 幻影读 |
   | -------------------------------- | ---- | ---------- | ------ |
   | READ-UNCOMMITTED**(读取未提交)** | √    | √          | √      |
   | READ-COMMITTED**(读取已提交)**   | ×    | √          | √      |
   | REPEATABLE-READ**(可重复读)**    | ×    | ×          | √      |
   | SERIALIZABLE**(可串行化)**       | ×    | ×          | ×      |

10. 可重复读实现原理？

    mvcc（多版本并发控制）。

    基于 undo log 版本链实现的 ReadView （一致性视图或者快照）机制

    铺垫了这么多，到这里终于可以说说什么是 Readiew 了。

    ReadView 说白了就是一种数据结构，它主要包含这样几部分：

    - m_ids，当前有哪些事务正在执行，且还没有提交，这些事务的 id 就会存在这里；
    - min_trx_id，是指 m_ids 里最小的值；
    - max_trx_id，是指下一个要生成的事务 id。下一个要生成的事务 id 肯定比现在所有事务的 id 都大；
    - creator_trx_id，每开启一个事务都会生成一个 ReadView，而 creator_trx_id 就是这个开启的事务的 id。

    ![img](D:\面试\面试题\img\mvcc.png)

    第一次读的时候，开启事务 A 的时候就生成了一个 ReadView，R                

    此时事务 A 第二次去查询的时候，先查到的是 trx_id = 18 的那条数据，它会发现 18 比最小的事务编号 10 大。那就说明事务编号为 18 的事务，有可能它是读不到的。

    接着就要去 m_ids 里确认是否有 18 这条数据了。发现有 18，那就说明在事务 A 开启事务的时候，这个事务是没有提交的，它修改的数据就不应该被读到。

    事务 A 就会顺着 roll_pointer 指针继续往下找，找到了 trx_id = 8 这条日志，发现这条能读，读到的值任然是 x，与第一次读到的结果一致。

    成功实现可重复读！

11. mysql锁机制

    分类：

    - 表级锁：**粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单 **，资源消耗也比较少，加锁快，不会出现死锁** 。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。

    - 行级锁：Mysql中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 InnoDB支持的行级锁，包括如下几种。

      ```txt
      Record Lock: 对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项；
      Gap Lock: 对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。
      Next-key Lock： 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题。
      ```

    进一步分类：

    - **共享锁（Share Locks，简记为S）又被称为读锁**，其他用户可以并发读取数据，但任何事务都不能获取数据上的排他锁，直到已释放所有共享锁。
    - **排它锁（(Exclusive lock,简记为X锁)）又称为写锁**，若事务T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。
    - **意向共享锁（IS）：** 表示事务准备给数据行记入共享锁，事务在一个数据行加共享锁前必须先取得该表的IS锁。
    - **意向排他锁（IX）：** 表示事务准备给数据行加入排他锁，事务在一个数据行加排他锁前必须先取得该表的IX锁。

    1. **这里的意向锁是表级锁，表示的是一种意向，仅仅表示事务正在读或写某一行记录，在真正加行锁时才会判断是否冲突。意向锁是InnoDB自动加的，不需要用户干预。**
    2. **IX，IS是表级锁，不会和行级的X，S锁发生冲突，只会和表级的X，S发生冲突。**

12. 怎么查看SQL执行过程？如何对SQL语句优化？explain参数？

    （1）使用explain命令查看sql执行过程。

    （2）sql优化：

    - 对查询进行优化，尽量避免全表扫描，首先考虑where、order by等字段建立索引
    - 应避免在where中使用！=、<>等操作符，否则进行全表扫描
    - 应避免在where中使用or来连接，否则进行全表扫描
    - 应避免在where中进行表达式操作、函数操作
    - 。。。。

    （3）explain参数：

    - id：**SQL执行的顺序的标识**

    - select-type：每个select子句的类型

    - table：哪张表

    - type：访问类型

      常用的类型有： **ALL, index, range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）**

    - possible-keys：**指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用**

    - Key：**key列显示MySQL实际决定使用的键（索引）**

    - key_len：*\*表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度\**

    - ref：**表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值**

    - rows：**表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数**

    - **Extra**：**包含MySQL解决查询的详细信息**
    
13. redolog、binlog、undolog详解

    （1）redolog重做日志（Innodb专有）

    - 作用：

    ​		确保事务的持久性。
    　　防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

    - 什么时候产生：
      事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。
    - 什么时候释放：
      当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。
    - 刷新到磁盘的时机：
      1. Redo log buffer空间不足时
      2. 事务提交
      3. 后台线程
      4. 做checkpoint
      5. 实例shutdown时
      6. binlog切换时

    （2）undolog（回滚日志）

    - 作用：
      保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读
    - 内容：
      逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。
    - 什么时候产生：
      事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性
    - 什么时候释放：
      当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。

    （3）binlog（二进制日志）

    - 作用：
      1，用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
      2，用于数据库的基于时间点的还原。
    - 内容：
      逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
      但又不完全是sql语句这么简单，而是执行的sql语句（增删改）反向的信息，
      也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。
      在使用mysqlbinlog解析binlog之后一些都会真相大白。
      因此可以基于binlog做到类似于[Oracle](https://www.linuxidc.com/topicnews.aspx?tid=12)的闪回功能，其实都是依赖于binlog中的日志记录。
    - 什么时候产生：
      事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
      这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。
      因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。
      这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。
    - 什么时候释放：
      binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。

#### 2.2 Redis

1. 简单介绍一下redis？

   redis是使用c语言开发的数据库，数据存储在内存中，读写速度非常快，广泛用于缓存。

   另外**Redis 除了做缓存之外，Redis 也经常用来做分布式锁，甚至是消息队列。**

   **Redis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。**

2. 说一下 Redis 和 Memcached 的区别？

   - redis数据类型更丰富，除了K/V键值对外，还支持list、set、zset、hash等结构。memcached只支持k/v
   - redis支持数据持久化
   - Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。
   - Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。
   - Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的.
   - Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。
   - Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。
   - Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。

3. Redis 常见数据结构以及使用场景分析？

   1. **SDS简单动态字符串**

      ![](D:\面试\面试题\img\sds.PNG)

      free属性：记录buf中未使用字节的数量；len：记录buf中已使用字节的数量，结尾的'\0'不统计；buf字节数组，用来存储字符串。

      **与c字符串的区别：**

      - 常数复杂度获取字符串的长度；
      - 杜绝缓冲区溢出；
      - 减少修改字符串带来的内存重分配次数
      - 可以保存文本和二进制数据

      **常用命令：**

       	get、set、strlen、exists、dect等

      **应用场景：**用得到字符串的地方

   2. **list链表**

      C语言没有链表，所以redis自己构造了**双向链表**，支持反向查找和遍历。

      ![](D:\面试\面试题\img\链表.PNG)

      **常用命令:** `rpush,lpop,lpush,rpop,lrange、llen` 等。

      **应用场景:** 发布与订阅或者说消息队列、慢查询。

   3. **hash结构**

      ![](D:\面试\面试题\img\字典.PNG)

      这里是一个字典dict，有两个哈希表ht[0]和ht[1]，哈希表里面table指向哈希表节点数组，每个哈希表节点存放key/value，**哈希冲突使用链地址法解决**，**rehash时每次空间扩大一倍**，适合存放对象。

      **常用命令：** `hset,hmset,hexists,hget,hgetall,hkeys,hvals` 等。

      **应用场景:** 系统中对象数据的存储。

   4. **set结构**

       set 类型是一种无序集合，集合中的元素没有先后顺序。可以基于 set 轻易实现交集、并集、差集的操作。

      **常用命令：** `sadd,spop,smembers,sismember,scard,sinterstore,sunion` 等。

      **应用场景:** 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景

   5. **sorted set**

      **介绍：** 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。

      **常用命令：** `zadd,zcard,zscore,zrange,zrevrange,zrem` 等。

      **应用场景：** 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。

4. redis单线程模型?

   Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。主要包含下面四个部分：

   - 多个 socket（客户端连接）
   - IO 多路复用程序（支持多个客户端连接的关键）
   - 文件事件分派器（将 socket 关联到相应的事件处理器）
   - 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

   ![img](D:\面试\面试题\img\redis事件处理器.png)

   产生的套接字都会进入队列中，以有序的、同步的、每次一个的方式向文件事件分派器发送。

5. redis为什么不用多线程？单线程的好处？

   - 单线程编程容易并且更容易维护；
   - Redis 的性能瓶颈不在 CPU ，主要在内存和网络；

   - 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

6. redis设置过期时间有什么用？怎么判断过期？过期策略？

   **Redis中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间 。另外， `persist` 命令可以移除一个键的过期时间： **

   用途：

   - 缓解内存的消耗
   - 业务场景就是需要某个数据只在某一时间段内存在

   判断过期方法：

   - Redis  通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。 

   过期删除策略：

   - **惰性删除** ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
   - **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。

7. redis内存淘汰机制？

   - **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰

   - **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰

   - **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰

   - **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）

   - **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰

   - **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

8. redis持久化

   1. 持久化快照RDB：Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。

      ```conf
      save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
      
      save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
      
      save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
      ```

   2. AOF追加文件持久化

      AOF 持久化 的实时性更好，因此已成为主流的持久化方案。开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。

      为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis  性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis  还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

   3. AOF重写问题

      AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。

      AOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。

      在重写过程中产生的数据库操作，redis会存入AOF重写缓冲区，重写完加到新AOF文件尾。

9. redis事务

   Redis 可以通过 **MULTI，EXEC，DISCARD 和 WATCH**  等命令来实现事务(transaction)功能。

   使用 MULTI命令后可以输入多个命令。Redis不会立即执行这些命令，而是将它们放到队列，当调用了[EXEC](https://redis.io/commands/exec)命令将执行所有命令。

   **Redis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。**

   为什么 Redis 不支持事务回滚？

   （1）大多数事务失败是因为**语法错误或者类型错误**，这两种错误，在开发阶段都是可以预见的。

   （2）Redis 为了**性能方面**就忽略了事务回滚。

10. 什么是缓存穿透？

    缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。

    解决办法：

    - 缓存无效key，过期时间设置短一点，防止黑客恶意攻击
    - 使用布隆过滤器。把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端。**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

11. 什么是缓存雪崩？

    **缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。**

    解决方法：

    - **针对 Redis 服务不可用的情况：**
      - 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
      - 限流，避免同时处理大量的请求。

    - **针对热点缓存失效的情况：**
      - 设置不同的失效时间比如随机设置缓存的失效时间。
      - 缓存永不失效。

12. 如何保证缓存和数据库数据的一致性？

    三种读写策略：

    （1）Cache Aside Pattern（旁路缓存模式）：平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。

    ​	写：先更新DB，再删除缓存；

    ​	读：从cache中读数据，读到就返回，读不到就从数据库读，然后写入缓存。

    问：可以先删除缓存再更新DB吗？

    ​		不行，会产生数据不一致问题，比如请求1先把cache中的A数据删除 -> 请求2从DB中读取数据->请求1再把DB中的A数据更新。

    问：那先更新DB，再删缓存就没问题吗？

    ​		不一定，也会产生不一致问题，如果删除缓存失败也会造成数据不一致。

    缺点：

    - 首次请求数据一定不在 cache 的问题

      解决：可以将热点数据可以提前放入cache 中。

    - 写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。

      解决：

      - 数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。
      - 可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

    （2）Read/Write Through Pattern（读写穿透）：服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 DB，从而减轻了应用程序的职责。

    ​	写：先查 cache，cache 中不存在，直接更新 DB。cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（同步更新 cache 和 DB）。

    ​	读：从 cache 中读取数据，读取到就直接返回 。读取不到的话，先从 DB 加载，写入到 cache 后返回响应。

    （3）Write Behind Pattern（异步缓存写入）：和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。

    两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。**

    Write Behind Pattern 下 DB 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。
    
13. redis主从复制？

    1. **旧版本**：分为同步（sync）和命令传播两种

       - 同步：

         ![image-20210307170252049](D:\面试\面试题\img\sync主从复制.png)

       - 命令传播：主服务器将自己的写命令发送给从服务器

       - 缺点：断线后重连需要进行完整重同步，非常耗费资源

    2. **新版本**：PSYNC命令，有完整重同步和部分重同步

       完整重同步用于初次连接或者重连后复制偏移量已经不在缓冲区内，部分重同步用于断线重连。

       - 复制偏移量：主从服务器分别维护的值offset
       - 复制积压缓冲区：主服务器维护的固定长度的队列

       ![image-20210307171000166](D:\面试\面试题\img\复制积压缓冲区.png)

       - 服务器运行ID：主从服务器都有自己的ID，断线重连后是一个主服务器，则可以进行部分重同步。

       ![image-20210307171212391](D:\面试\面试题\img\PSYNC.png)

    3. **复制的实现：**

       （1）设置主服务器地址和端口

       （2）建立套接字连接

       （3）发送ping命令

       （4）身份验证

       （5）从服务器向主服务器发送端口信息

       （6）同步PSYNC

       （7）命令传播

    4. 心跳检测：

       从服务器每秒一次发送命令，里面有复制偏移量

       - 检测主从服务器的连接状态
       - 辅助实现min-slaves
       - 检测命令丢失

14. redis哨兵机制？

    - Sentinel是一个运行在特殊模式下的redis服务器，使用了和普通模式不一样的命令表，能够使用的命令和普通的redis命令不一样
    - Sentinel会读取用户指定的配置文件，为每个要被监视的主服务器创建相应的实例结构，并创建连向主服务器的命令连接和订阅连接，其中命令连接负责向主服务器发送命令，订阅连接用于接收指定频道的消息
    - Sentinel通过向主服务器发送INFO命令来获取主服务器下所有从服务器的地址信息，并为这些从服务器创建相应的实例，以及连向这些从服务器的命令连接和订阅连接。
    - 一般情况下，Sentinel以每十秒一次的频率向被监视的主服务器和从服务器发送INFO命令，当主服务器下线的时候，或者Sentinel进行故障转移的时候，Sentinel向从服务器发送的INFO命令变为每秒1次。
    - 对于监视同一个主服务器和从服务器的多个Sentinel来说，他们会以每2秒一次的频率，通过向被监视服务器的hello频道发送信息来向其他Sentinel宣告自己的存在。
    - 每个Sentinel也会从hello频道中接收其他Sentinel发来的信息，并根据这些信息为其他sentinel创建相应的实例以及命令连接。
    - Sentinel只会与主服务器和从服务器创建命令连接和订阅连接，Sentinel与Sentinel之间则只创建命令连接。
    - Sentinel以每秒一次的频率向实例（主服务器、从服务器、其他sentinel）发送ping命令，根据ping命令的回复来判断实例是否在线。当一个实例在指定时长连续向sentinel发送无效回复，sentinel会将这个实例判断为主观下线。
    - sentinel判断一个服务器是主观下线后，会向同样监视这个主服务器的sentinel进行询问，看他们是否同意该服务器已经下线。超过半数的sentinel认为服务器下线，则认为主服务器已经客观下线。
    - 主服务器客观下线后，进行故障转移。首先选出领头Sentinel，然后领头sentinel根据规则选出一个从服务器作为新的主服务器，然后给其余从服务器发送命令复制新的主服务器，将旧主服务器变成新的主服务器的从服务器。

15. redis集群？

    ![image-20210307221745172](D:\面试\面试题\img\redis集群.png)
    
16. redis的基本对象及其编码？

    五个基本对象：字符串**String**、列表**list**、哈希表**hash**、集合**set**、有序集合**zset**

    编码常量：HT字典、LinkedList双端链表、ziplist压缩列表、intset整数集合、skiplist跳表

    ![img](https://img2020.cnblogs.com/blog/1765333/202005/1765333-20200510215310518-816627373.png)

17. redis为什么使用跳表而不使用红黑树？

    - 实现简单
    - 范围查找方便（查找单个key，skiplist和平衡树的时间复杂度都为O(log n)）
    
18. 介绍一下跳表数据结构？

    (1) 由很多层结构组成
    
    (2) 每一层都是一个有序的链表
    
    (3) 最底层(Level 1)的链表包含所有元素
    
    (4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。
    
    (5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素
    
    ![img](https://img-blog.csdn.net/20170609153042962?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYmlndHJlZV8zNzIx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
    
19. redis数据结构

    （1）整数集合

    - 包含三个字段：encoding编码（16位，32位和64位）、length数组长度、contents[]数组

    - 数组中的每一项都按照从小到大的顺序排列，且不重复。

    - 升级：新加数据时，根据加入的数据类型分配空间；如果数据位数变大，之前的数据也要转变类型，并将之前的数据放到对应的空间，

      升级的好处是提高灵活性、节省空间

    （2）压缩列表

    压缩列表是redis为了节约内存开发的，由一系列特殊编码的**连续内存块**组成的**顺序性数据结构**

    - 字段：zlbytes（4字节）记录整个列表占用的内存字节数；ztail（4字节）记录表尾节点距离压缩列表起始地址有多少字节；

      zllen（2字节）记录压缩列表包含的节点数量；entryX列表节点；zlend（1字节）压缩列表末端

    - entryX列表节点也有三个字段：previous_entry_length记录了前一个节点的长度，本身有1个字节或者5个字节，通过当前地址减去pre属性的值就能得出前一个节点的位置，从而实现从表尾到表头的遍历；encoding属性记录了content保存的数据类型以及长度；content负责保存数据。

    - 连锁更新：如果前一个节点长度小于254字节，pre属性只要一个字节保存这个长度值，否则用5个字节保存。假如新加的节点长度大于254，则e1节点需要5个字节的pre来保存，结果导致e1的长度也超过254，e2节点的pre也需要变成5个字节，以此类推形成连锁更新。

    - 如果连锁更新涉及的节点数量不多，不会造成什么性能影响，平均复杂度为O(n)

    （3）字典

    - 字典字段：type和privdata属性是针对不同类型的键值对，为创建多态字典而设置的；ht属性是包含了两个项的数组，每一项都是一个哈希表，一般情况下只是用ht[0]哈希表，ht[1]哈希表只有在ht[0]哈希表rehash时使用；rehashidx属性记录目前rehash的进度，没有则是-1。
    - 哈希表字段：table是一个数组，数组中每一个元素指向一个哈希节点；size记录哈希表大小；sizemask就是size-1，计算下标用的；used记录已有节点数量。
    - 链地址法解决hash冲突
    - rehash算法：为字典ht[1]分配空间，大小为大于等于ht[0].used*2的2的n次方；然后将ht[0]上的值rehash到ht[1]上，全部迁移后，释放ht[0]，ht[1]置为ht[0]，新建ht[1]空表。
    - rehash的时机：
      - 服务器没有进行BGSAVE，负载因子大于等于1
      - 服务器正在执行BGSAVE，负载因子大于等于5
      - 负载因子小于0.1时会进行收缩操作
    - 渐进式rehash，就是分批次的进行rehash转移，通过rehashidx记录；这个时候的更新、查找、删除等操作会在两个哈希表上进行

    （4）跳表

    - 字段：header跳跃表表头；tail跳跃表表尾；level目前跳跃表内最高层数，表头不算；length目前跳表内节点数，表头不算
    - 跳表节点字段：level：记录各个层，用L1、L2、L3等标记，包含前进指针和跨度两个属性；backword后退指针；score分值，节点按各自的分值从小到大排列；obj成员对象，节点保存的成员对象。（分值相同，按照对象大小排序）
    - 平均时间复杂度为O(logn)

### 3. 计算机网络

1. 五层协议体系结构？

   从上到下：

   - 应用层：**通过应用进程间的交互来完成特定网络应用。**比如DNS、HTTP、SMTP等
   - 运输层：TCP提供**面向连接**的，**可靠的**数据传输服务。UDP提供**无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）。
   - 网络层：使用IP协议
   - 数据链路层：**数据链路层将网络层交下来的 IP 数据报组装成帧**，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。
   - 物理层：在物理层上所传送的数据单位是比特。

2. TCP三次握手和四次挥手？

   三次握手：

   ![TCP三次握手](D:\面试\面试题\img\三次握手2.png)

   （1）为什么要三次握手？

   三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方**确认自己与对方的发送与接收是正常的**。

   第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

   第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

   第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

   所以三次握手就能确认双发收发功能都正常，缺一不可。

   （2）第二次握手传回了ACK，为什么要传回SYN？

   接收端传回发送端所发送的ACK是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传SYN则是为了建立并确认从服务端到客户端的通信

   四次挥手：

   ![TCP四次挥手](D:\面试\面试题\img\TCP四次挥手.png)

   - 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
   - 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号
   - 服务器-关闭与客户端的连接，发送一个FIN给客户端

   任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。

3. TCP协议如何保证可靠传输？

   - TCP将应用数据分割成合适大小的数据包，并进行编号；接收方对包进行排序，将有序数据传给应用层
   - **校验和**：TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 
   - TCP接收端会丢弃重复的数据
   - **流量控制：**TCP  连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
   - **拥塞控制：** 当网络拥塞时，减少数据的发送。
   - **ARQ协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
   - **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 

4. 什么是ARQ协议？

   **自动重传请求**（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。

   （1）停止等待ARQ协议

   基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。

   优点：简单；缺点：信道利用率低，等待时间长。

   四种情况：

   - 无差错情况，发送接收正常

   - 超时重传：只要超过一段时间仍然没有收到确认，就重传前面发送过的分组；

   - 确认丢失：确认消息在传输过程丢失。

   - 确认迟到：确认消息在传输过程中迟到。

     ![](D:\面试\面试题\img\等待ARQ.PNG)

   三个要点：

   - 保留已发送分组的副本（可能要重传）
   - 必须进行编号
   - 超时计时器的重传时间应当比在分组传输的平均往返时间长
   

（2）连续ARQ协议

发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

优点 ：信道利用率高，容易实现，即使确认丢失，也不必重传。

缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条  消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫  Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

5. 滑动窗口和流量控制？

   **TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

6. 拥塞控制？

   为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。

   四种算法：

   - 慢开始：  慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。

   - 拥塞避免：也就是每个传输轮次，拥塞窗口cwnd只能线性加一，而不是像慢开始算法时，每个传输轮次，拥塞窗口cwnd按指数增长。

   - ![img](D:\面试\面试题\img\拥塞控制.png)

   - 快速重传和快恢复：

     ![img](D:\面试\面试题\img\快重传.png)

     ![img](D:\面试\面试题\img\快恢复1.png)

     ![img](D:\面试\面试题\img\快恢复2.png)
   
7. 流量控制和拥塞控制的区别？

   拥塞控制是确保子网可以承受所达到的流量，是一个**全局性问题**，涉及到全部主机、路由器等问题；而流量控制是端到端的控制。

8. 在浏览器中输入url地址到显示页面的过程?

   1. DNS解析

      DNS解析是一个递归查询的过程，首先在本地域名服务器查询，没有的话就会一级一级向上查询；

      DNS缓存：从离浏览器的距离排序的话，有以下几种: 浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。

      DNS负载均衡，可以返回一个合适的机器的IP给用户，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。

   2. TCP连接

   3. 发送HTTP请求

   4. 服务器处理请求并返回HTTP报文

   5. 浏览器解析渲染页面

   6. 连接结束

   ![img](D:\面试\面试题\img\url输入到展示出来的过程.jpg)

9. 常见的状态码？

   - 2XX 成功
     - 200 成功；
     - 204 请求成功但没有返回；
     - 206 客户端请求一部分资源，服务端成功，返回一部分资源
   - 3XX 重定向
     - 301 永久性重定向；
     - 302 临时性重定向；
     - 303 由于请求对应的资源存在着另一个 URI，应使用 GET方法定向获取请求的资源
     - 304 表示在客户端采用带条件的访问某资源时，服务端找到了资源，但是这个请求的条件不符合。跟重定向无关
     - 307 和302一样
   - 4XX 客户端错误
     - 400 请求报文存在语法错误
     - 401 需要认证（第一次返回）或者认证失败（第二次返回）
     - 403 forbidden请求被服务器拒绝
     - 404 not found服务器找不到资源
   - 5XX 服务器错误
     - 500 服务端执行请求时发生了错误
     - 503 服务器正在超负载或者停机维护，无法处理请求

10. Http的长连接与短连接？

    HTTP的长连接和短连接本质上是TCP长连接和短连接。在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议。

    短连接对于服务器来说管理较为简单，存在的连接都是有用的连接，不需要额外的控制手段。但如果客户请求频繁，将在TCP的建立和关闭操作上浪费较多时间和带宽。

    **长连接**可以**省去较多的TCP建立和关闭的操作，减少浪费，节约时间**。对于频繁请求资源的客户来说，较适用长连接。不过这里**存在一个问题**，**存活功能的探测周期太长**。

11. http是无状态协议，如何保存用户状态？

    使用session机制，在服务器端保存session可以用redis或者数据库，客户端通过在cookie中加session ID来追踪。如果cookie被禁用，最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。

12. cookie和session的区别?

    **Cookie 一般用来保存用户信息** 比如①我们在 Cookie  中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token  重写)；③登录一次网站后访问网站其他页面不需要重新登录。

    **Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

    Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。

13. http和https的区别？

    **端口** ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。

    **安全性和资源消耗：**  HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有  HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

    - 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等；
    - 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。
    
14. https加密过程？对称加密？非对称加密？中间人攻击？

    **什么是对称加密？**

    就是有一个密钥，它可以对一段内容加密，加密后只能用它才能解密看到原本的内容，和我们日常生活中用的钥匙作用差不多。

    **用对称加密可行吗？**

    **如果通信双方都各自持有同一个密钥，且没有别人知道，这两方的通信安全当然是可以被保证的（除非密钥被破解）。**
    然而最大的问题就是**这个密钥怎么让传输的双方知晓，同时不被别人知道**。如果由服务器生成一个密钥并传输给浏览器，那这个传输过程中密钥被别人劫持弄到手了怎么办？之后他就能用密钥解开双方传输的任何内容了，所以这么做当然不行。

    **什么是非对称加密？**

    有两把密钥，通常一把叫做公钥、一把叫做私钥，用公钥加密的内容必须用私钥才能解开，同样，私钥加密的内容只有公钥能解开。

    **用非对称加密可行吗？**
    鉴于非对称加密的机制，我们可能会有这种思路：服务器先把公钥直接明文传输给浏览器，之后浏览器向服务器传数据前都先用这个公钥加密好再传，这条数据的安全似乎可以保障了！**因为只有服务器有相应的私钥能解开这条数据**。然而**由服务器到浏览器的这条路怎么保障安全？**如果服务器用它的的私钥加密数据传给浏览器，那么浏览器用公钥可以解密它，而这个公钥是一开始通过明文传输给浏览器的，这个公钥被谁劫持到的话，他也能用该公钥解密服务器传来的信息了。所以**目前似乎只能保证由浏览器向服务器传输数据时的安全性**

    **非对称加密+对称加密？**

    既然非对称加密耗时，非对称加密+对称加密结合可以吗？而且得尽量减少非对称加密的次数。当然是可以的，而且非对称加密、解密各只需用一次即可。
    请看一下这个过程：

    1. 某网站拥有用于非对称加密的公钥A、私钥A’。
    2. 浏览器像网站服务器请求，服务器把公钥A明文给传输浏览器。
    3. 浏览器随机生成一个用于对称加密的密钥X，用公钥A加密后传给服务器。
    4. 服务器拿到后用私钥A’解密得到密钥X。
    5. 这样双方就都拥有密钥X了，且别人无法知道它。之后双方所有数据都用密钥X加密解密。

    完美！HTTPS基本就是采用了这种方案。完美？还是有漏洞的。

    **中间人攻击**

    中间人的确无法得到浏览器生成的密钥B，这个密钥本身被公钥A加密了，只有服务器才有私钥A’解开拿到它呀！然而中间人却完全不需要拿到密钥A’就能干坏事了。请看：

    1. 某网站拥有用于非对称加密的公钥A、私钥A’。
    2. 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。
    3. **中间人劫持到公钥A，保存下来，把数据包中的公钥A替换成自己伪造的公钥B（它当然也拥有公钥B对应的私钥B’）**。
    4. 浏览器随机生成一个用于对称加密的密钥X，用**公钥B**（浏览器不知道公钥被替换了）加密后传给服务器。
    5. **中间人劫持后用私钥B’解密得到密钥X，再用公钥A加密后传给服务器**。
    6. 服务器拿到后用私钥A’解密得到密钥X。

    这样在双方都不会发现异常的情况下，中间人得到了密钥B。**根本原因是浏览器无法确认自己收到的公钥是不是网站自己的**。

    **数字证书**

    网站在使用HTTPS前，需要向“**CA机构**”申请颁发一份**数字证书**，数字证书里有证书持有者、证书持有者的公钥等信息，服务器把证书传输给浏览器，浏览器从证书里取公钥就行了，证书就如身份证一样，可以证明“该公钥对应该网站”。

    **如何放防止数字证书被篡改？**

    我们把证书内容生成一份“签名”，比对证书内容和签名是否一致就能察觉是否被篡改。这种技术就叫`数字签名`。数字签名的制作过程：

    1. CA拥有非对称加密的私钥和公钥。
    2. CA对证书明文信息进行hash。
    3. 对hash后的值用私钥加密，得到数字签名。

    **Https连接过程：**

    ① 客户端的浏览器向服务器发送请求，并传送客户端 SSL 协议的版本号，加密算法的种类，产生的随机数，以及其他服务器和客户端之间通讯所需要的各种信息。

    ② 服务器向客户端传送 SSL 协议的版本号，加密算法的种类，随机数以及其他相关信息，同时服务器还将向客户端传送自己的证书。

    ③ 客户端利用服务器传过来的信息验证服务器的合法性，服务器的合法性包括：证书是否过期，发行服务器证书的 CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的 "发行者的数字签名"，服务器证书上的域名是否和服务器的实际域名相匹配。如果合法性验证没有通过，通讯将断开；如果合法性验证通过，将继续进行第四步。

    ④ 用户端随机产生一个用于通讯的 "对称密码"，然后用服务器的公钥（服务器的公钥从步骤②中的服务器的证书中获得）对其加密，然后将加密后的“预主密码”传给服务器。

    ⑤ 如果服务器要求客户的身份认证（在握手过程中为可选），用户可以建立一个随机数然后对其进行数据签名，将这个含有签名的随机数和客户自己的证书以及加密过的密钥一起传给服务器。

    ⑥ 如果服务器要求客户的身份认证，服务器必须检验客户证书和签名随机数的合法性，具体的合法性验证过程包括：客户的证书使用日期是否有效，为客户提供证书的 CA  是否可靠，发行 CA 的公钥能否正确解开客户证书的发行 CA 的数字签名，检查客户的证书是否在证书废止列表（CRL）中。检验如果没有通过，通讯立刻中断；如果验证通过，服务器将用自己的私钥解开加密的私钥，然后执行一系列步骤来产生主通讯密码（客户端也将通过同样的方法产生相同的主通讯密码）。

    ⑦ 服务器和客户端用相同的对称加密密钥，对称密钥用于 SSL 协议的安全数据通讯的加解密通讯。同时在 SSL 通讯过程中还要完成数据通讯的完整性，防止数据通讯中的任何变化。

    ⑧ 客户端向服务器端发出信息，指明后面的数据通讯将使用的步骤 ⑦ 中的主密码为对称密钥，同时通知服务器客户端的握手过程结束。

    ⑨ 服务器向客户端发出信息，指明后面的数据通讯将使用的步骤 ⑦ 中的主密码为对称密钥，同时通知客户端服务器端的握手过程结束。

    ⑩ SSL 的握手部分结束，SSL 安全通道的数据通讯开始，客户和服务器开始使用相同的对称密钥进行数据通讯，同时进行通讯完整性的检验。

15. http1.x和http2.0的区别？

    - http2.0使用二进制格式而不是文本
    - http2.0使用多路复用，解决了http1.x存在的线端阻塞问题，即一个连接(connection)一次只提交一个请求的效率比较高, 多了就会变慢。
    - http2.0使用报头压缩，降低了开销
    - Http2.0让服务器可以将响应主动“推送”到客户端缓存中

16. RPC和http的区别？

    （1）传输协议：
    
    ​	RPC，可以基于TCP协议，也可以基于HTTP协议
    
    ​    HTTP，基于HTTP协议
    
    （2）传输效率：
    
    ​	RPC，使用自定义的TCP协议，可以让请求报文体积更小，或者使用HTTP2协议，也可以很好的减少报文的体积，提高传输效率
    
    ​    HTTP，如果是基于HTTP1.1的协议，请求中会包含很多无用的内容，如果是基于HTTP2.0，那么简单的	封装以下是可以作为一个RPC来使⽤用的，这时标准RPC框架更多的是服务治理
    
    （3）性能消耗：
    
    ​	RPC可以基于thrift实现高效二进制传输
    
    ​	HTTP大部分使用JSON格式，序列化比较耗时
    
    （4）负载均衡
    
    ​	RPC基本自带负载均衡，HTTP需要配置nginx
    
    （5）服务治理**（下游服务新增、重启、下线时如何不影响上游调用者）**：
    
     	RPC，能做到自动通知，不影响上游 
    
    ​    HTTP，需要事先通知，修改Nginx/HAProxy配置
    
    **RPC主要用于公司内部的服务调用，性能消耗低，传输效率高，服务治理方便。HTTP主要用于对外的异构环境，浏览器器接口调用，APP接口调用，第三方接口调用等。**
    
17. **TIME_WAIT的意义**？

    （1）可靠地实现TCP全双工连接的终止

    为了保证A发送的最后一个ACK报文段能够到达B。

    A给B发送的ACK可能会丢失，B收不到A发送的确认，B会超时重传FIN+ACK报文段，此时A处于2MSL时间内，就可以收到B重传的FIN+ACK报文段，接着A重传一次确认，重启2MSL计时器。最后，A和B都能够正常进入到CLOSED状态。

    如果A在发完ACK后直接立即释放连接，而不等待一段时间，就无法收到B重传的FIN+ACK报文段，也就不会再次发送确认报文段，这样，B就无法按照正常步骤进入CLOSED状态。

    （2）允许旧的报文段在网络中消逝 （也就是不会影响下次连接）

    A发送确认后，该确认报文段可能因为路由器异常在网络中发生“迷途”，并没有到达B，该确认报文段可以称为旧的报文段。A在超时后进行重传， 发送新的报文段，B在收到新的报文段后进入CLOSED状态。在这之后，发生迷途的旧报文段可能到达了B，通常情况下，该报文段会被丢弃，不会造成任何的影响。但是如果两个相同主机A和B之间又建立了一个具有相同端口号的新连接，那么旧的报文段可能会被看成是新连接的报文段，如果旧的报文段中数据的任何序列号恰恰在新连接的当前接收窗口中，数据就会被重新接收，对连接造成破坏。为了避免这种情况，TCP不允许处于TIME_WAIT状态的连接启动一个新的连接，因为TIME_WAIT状态持续2MSL，就可以保证当再次成功建立一个TCP连接的时，来自之前连接的旧的报文段已经在网络中消逝，不会再出现在新的连接中。

18. 服务器端产生大量time_wait的原因？

    - 高并发
    - 服务器主动关闭连接，如果服务器不主动关闭连接,那么TIME_WAIT就是客户端的事情了

19. 如果服务器端确实存在大量的TIME_WAIT，那么会导致什么问题呢？

    **首先先明确TIME_WAIT状态占用的到底是什么**

    被占用的是一个五元组(协议,本地IP,本地端口,远程IP,远程端口)
    对于Web服务器，协议是TCP,本地ip也只有一个,端口一般是80或者433或8080(固定的)，只剩下远程IP和远程端口可用了,如果远程IP相同的话，就只有远程端口可用了，远程端口只有几万个,所以当同一客户端向服务器建立了大量连接的话，可用的五元组会耗尽导致问题

    现在我们知道了大量的TIME_WAIT会占用大量的五元组

    **那么五元组什么时候会耗尽呢？**

    当客户端通过应用层的负载均衡代理到服务器导致进入服务器的ip地址只有几个的话，可能会导致五元组耗尽！

    解决方法1:服务器不主动关闭连接,那么这个问题就是客户端应该解决的了~(TIME_WAIT将不会产生)

    解决方法2:增加客户端IP(一般客户端IP少都是通过应用层的负载均衡到达服务器的)(五元组将不会耗尽)

    解决方法3:设置允许地址重用,这样每次bind的时候，如果五元组正在使用,bind就会把五元组抢过来(不安全

20. tcp报文

    ![img](https://farm1.staticflickr.com/792/27194088468_4cb0141fc8_b.jpg)

21. UDP报文？

    ![pIYBAF_hWV6ARdMsAADy2TP19Uo693.png](https://file.elecfans.com/web1/M00/D6/5A/pIYBAF_hWV6ARdMsAADy2TP19Uo693.png)

22. UDP如何进行校验过程？

    ![img](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=2503298409,3583390257&fm=26&gp=0.jpg)

    **伪首部**（伪的是ip首部，17就是ip数据报首部协议字段）只有在计算校验和的时候才会出现，既不会向上也不会向下传递。

    - 发送端：填上伪首部；全0填充校验和字段；全0填充数据部分；伪首部+首部+数据采用二进制反码求和；把和求反码填入校验和字段；去掉伪首部发送
    - 接收端：填上伪首部；伪首部+首部+数据采用二进制反码求和（与发送端不同的是，此时校验和字段不是全0）；结果全为1则没错，否则丢弃。

    TCP校验和和UDP一样。

23. http报文？

    ![img](https://img-blog.csdn.net/20180322214413108)

    ![img](https://img-blog.csdn.net/20180322214428181)

    **请求报文**：

    - 请求行：第一行，由方法字段、URL和HTTP协议版本字段组成
    - 请求首部：位于请求行下面，包括Host、User-Agent、Accept等
    - 通用首部：请求和响应都能使用的
    - 实体首部：用于指定实体属性，用于POST方法中

    **响应报文：**

    - 状态行：协议版本、状态码、原因短语
    - 响应首部：状态行下面，包括Date、Server等
    - 通用首部：请求和响应都能使用的
    - 实体首部：实体包含了Web客户端请求的对象。Content-Length标头及Content-Type标头用于计算实体的位置、数据类型和数据长度。

24. TCP粘包拆包？

    首先**UDP不存在粘包问题**，因为UDP是基于报文发送的，报文首部有16bit来指示UDP数据报文的长度，在应用层能很好地区分，避免了粘包和拆包问题。

    TCP是基于字节流，报文中没有指示数据长度的字段，可能发生粘包拆包的问题。

    **发生原因：**

    - 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
    - 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。
    - 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。
    - 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

    **解决办法：**

    - 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
    - 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
    - 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。
    
25. get和post的区别

    - get在回退时无害，post回退时会再次提交请求
    - get请求会被浏览器主动缓存，post不会
    - get只能进行url编码，post支持多种编码方式
    - get在URL中传递的参数是有长度限制的，post没有
    - post更加安全，因为get的参数直接暴露在URL上面，不能用来传递敏感信息
    - get参数通过url传递，post参数放在request body上面。

    post其实并不安全，只要进行抓包就能看到数据，所以传递密码需要进行加密。

### 4.操作系统

1. 用户态和核心态的区别?

   - **内核态与用户态是操作系统的两种运行级别，当程序运行在3级特权级上时，就可以称之为运行在用户态。**因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；
   - **当程序运行在0级特权级上时，就可以称之为运行在内核态。**
   - **运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。**
   - **这两种状态的主要差别是**：
     - 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理机是可被抢占的；
     - 而处于核心态执行中的进程，则能访问所有的内存空间和对象，且所占有的处理机是不允许被抢占的。

   通常有三种情况会产生用户态到内核态的切换;

   - 系统调用

     **这是用户态进程主动要求切换到内核态的一种方式**，**用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作**

   - 异常

     当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

   - 外围设备中断

     **当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号**，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，

2. 进程的通信方式?

   每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信**

   ![img](D:\面试\面试题\img\进程通信.png)

   （1）管道/匿名管道

   - 管道是半双工的，数据只能向一个方向流动；需要双方通信时，建立两个管道。
   - 只能用于父子进程或者兄弟进程
   - 构成一种独立的文件系统，只存在于内存中
   - 实质：管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或者写进程进入等待队列，当空的缓冲区有新数据写入或者满的缓冲区有数据读出来时，就唤醒等待队列中的进程继续读写。
   - 局限：只支持单向数据流；只能用于亲戚进程等

   （2）有名管道

   - 它提供了一个路径名与之关联，**以有名管道的文件形式存在于文件系统中**，这样，**即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信**
   - 严格遵循**先进先出(first in first out)**,对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。
   - **有名管道的名字存在于文件系统中，内容存放在内存中。**

   匿名管道阻塞问题：无名管道无需显示打开，创建时直接返回文件描述符，在读写时需要确定对方的存在，否则将退出。如果当前进程向无名管道的一端写数据，必须确定另一端有某一进程。如果写入无名管道的数据超过其最大值，写操作将阻塞，如果管道中没有数据，读操作将阻塞，如果管道发现另一端断开，将自动退出。

   有名管道阻塞问题：有名管道在打开时需要确实对方的存在，否则将阻塞。即以读方式打开某管道，在此之前必须一个进程以写方式打开管道，否则阻塞。此外，可以以读写（O_RDWR）模式打开有名管道，即当前进程读，当前进程写，不会阻塞。

   （3）信号

   - 信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。

   - 如果该进程当前并未处于执行状态，则该信号就有内核保存起来，知道该进程恢复执行并传递给它为止。

   - 如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。

   - 常见的信号有：

     | 1    | SIGHUP  | 该信号让进程立即关闭.然后重新读取配置文件之后重启            |
     | ---- | ------- | ------------------------------------------------------------ |
     | 2    | SIGINT  | 程序中止信号，用于中止前台进程。相当于输出 Ctrl+C 快捷键     |
     | 8    | SIGFPE  | 在发生致命的算术运算错误时发出。不仅包括浮点运算错误，还包括溢出及除数为 0 等其他所有的算术运算错误 |
     | 9    | SIGKILL | 用来立即结束程序的运行。本信号不能被阻塞、处理和忽略。般用于强制中止进程 |
     | 14   | SIGALRM | 时钟定时信号，计算的是实际的时间或时钟时间。alarm 函数使用该信号 |
     | 15   | SIGTERM | 正常结束进程的信号，kill 命令的默认信号。如果进程已经发生了问题，那么这 个信号是无法正常中止进程的，这时我们才会尝试 SIGKILL 信号，也就是信号 9 |
     | 18   | SIGCONT | 该信号可以让暂停的进程恢复执行。本信号不能被阻断             |
     | 19   | SIGSTOP | 该信号可以暂停前台进程，相当于输入 Ctrl+Z 快捷键。本信号不能被阻断 |

   （4）消息队列

   - 消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。
   - 与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
   - 另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达

   （5）共享内存

   - 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。

   - 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。

   - 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。

   （6）信号量

   - 信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。

   （7）套接字

   - 套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。
   - 套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。
   - 特性：域、端口号、协议类型
     - 域：一是AF_INET，它指的是Internet网络。另一个域AF_UNIX，表示UNIX文件系统
     - 端口号：端口是一个信息缓冲区，用于保留Socket中的输入/输出信息，端口号是一个16位无符号整数，范围是0-65535。每一个套接字都组合进了IP地址、端口，这样形成的整体就可以区别每一个套接字。
     - 套接字协议类型：
       - **一是流套接字，**流套接字在域中通过TCP/IP连接实现，同时也是AF_UNIX中常用的套接字类型。流套接字提供的是一个有序、可靠、双向字节流的连接，因此发送的数据可以确保不会丢失、重复或乱序到达，而且它还有一定的出错后重新发送的机制。
       - **二个是数据报套接字，**它不需要建立连接和维持一个连接，它们在域中通常是通过UDP/IP协议实现的。
       - **三是原始套接字，**原始套接字允许对较低层次的协议直接访问，比如IP、 ICMP协议，它常用于检验新的协议实现

3. 进程/线程间的同步方式？

   1. **临界区**：在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。
   2. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
   3. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
   4. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操

4. 进程调度的时机？什么时候不能进行进程调度？

   调度时机：

   （1）主动放弃：

   - 进程正常终止
   - 运行中发生异常而终止
   - 主动阻塞

   （2）被迫放弃：

   - 时间片用完
   - 有更紧急的时间处理（如IO中断）
   - 有更高优先级的进程进入就绪队列

   不能进行调度情况：

   - 处理中断过程
   - 进程在操作系统内核程序临界区中
   - 原子操作过程

5. 进程的调度算法？

   - **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
   - **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
   - **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
   - **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
   - **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

6. 常见的几种内存管理机制?

   1. **块式管理** ：  远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
   2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
   3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多  。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。  段式管理通过段表对应逻辑地址和物理地址。
   4. **段页式管理机制** 。段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。

7. 分页机制和分段机制有哪些共同点和区别？

   1. 共同点
      - 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
      - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
   2. 区别
      - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
      - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

8. 介绍一下快表和多级页表？

   （1）快表（存放在高速缓存器）：

   为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的  Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU  要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。**（和redis的原理很相似）**

   （2）多级页表

   引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。

9. 什么是虚拟地址？为什么要使用虚拟地址？

   我们编程一般只有可能和逻辑地址打交道，比如在 C  语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

   **如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

   虚拟地址的优势：

   - 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
   - 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
   - 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

10. 什么是虚拟内存？

   -  **虚拟内存** 可以让程序可以拥有超过系统物理内存大小的可用内存空间
   - **虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。
   - **虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**。

11. 局部性原理？

    1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
    2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

12. 什么是页面置换算法？

    地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。

    当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。（就像redis的内存淘汰机制）

    - **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
    - **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
    - **LRU （Least Currently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
    - **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** :  该置换算法选择在之前时期使用最少的页面作为淘汰页。

13. Linux文件类型？

    - **普通文件（-）** ： 用于存储信息和数据， Linux 用户可以根据访问权限对普通文件进行查看、更改和删除。比如：图片、声音、PDF、text、视频、源代码等等。
    - **目录文件（d，directory file）** ：目录也是文件的一种，用于表示和管理系统中的文件，目录文件中包含一些文件名和子目录名。打开目录事实上就是打开目录文件。
    - **符号链接文件（l，symbolic link）** ：保留了指向文件的地址而不是文件本身。
    - **字符设备（c，char）** ：用来访问字符设备比如硬盘。
    - **设备文件（b，block）** ： 用来访问块设备比如硬盘、软盘。
    - **管道文件(p,pipe)** : 一种特殊类型的文件，用于进程之间的通信。
    - **套接字(s,socket)** ：用于进程间的网络通信，也可以用于本机之间的非网络通信。

14. 常用的linux命令？

    - cd 切换目录
    - ls 查看文件与目录
    - cp 复制文件
    - mv 移动文件、目录或者更名
    - rm 删除文件
    - ps 将某个时间点的进程运行情况选取下来并输出
    - kill 杀死进程
    - file 判断接在file命令后的文件的基本数据
    - cat 查看文本内容
    - vim 使用vim编辑器
    - tar 解压缩命令

15. 零拷贝技术？

    减少数据在内核态和用户态之间进行来回拷贝。

    （1）使用mmap()

    应用程序调用mmap()，磁盘上的数据会通过DMA被拷贝的内核缓冲区，接着操作系统会把这段内核缓冲区与应用程序共享，这样就不需要把内核缓冲区的内容往用户空间拷贝。应用程序再调用write(),操作系统直接将内核缓冲区的内容拷贝到socket缓冲区中，这一切都发生在内核态，最后，socket缓冲区再把数据发到网卡去。

    ![img](https://img2020.cnblogs.com/other/1218593/202004/1218593-20200401102939176-878827018.png)

    但是mmap()使用时，如果被另一个进程终止，write()系统调用会因为访问非法地址而被SIGBUS信号终止。解决方法：

    - 为SIGBUS信号建立信号处理程序
    - 使用文件租借锁。在文件描述符上使用租借锁，我们为文件向内核申请一个租借锁，当其它进程想要截断这个文件时，内核会向我们发送一个实时的RTSIGNALLEASE信号，告诉我们内核正在破坏你加持在文件上的读写锁。这样在程序访问非法内存并且被SIGBUS杀死之前，你的write系统调用会被中断。write会返回已经写入的字节数，并且置errno为success。

    （2）sendFile()

    sendfile系统调用利用DMA引擎将文件内容拷贝到内核缓冲区去，然后将带有文件位置和长度信息的缓冲区描述符添加socket缓冲区去，这一步不会将内核中的数据拷贝到socket缓冲区中，DMA引擎会将内核缓冲区的数据拷贝到协议引擎中去，避免了最后一次拷贝。

    ![img](https://img2020.cnblogs.com/other/1218593/202004/1218593-20200401102939687-1946644767.png)

    （3）mmap和sendFile的区别？

    - mmap 适合小数据量读写，sendFile 适合大文件传输。
    - mmap 需要 4 次上下文切换，3 次数据拷贝；sendFile 需要 3 次上下文切换，最少 2 次数据拷贝。
    - sendFile 可以利用 DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。

    在这个选择上：rocketMQ 在消费消息时，使用了 mmap。kafka 使用了 sendFile。

### 5.框架

#### 5.1 spring

1. 什么是ioc？

   IoC（Inverse of Control:控制反转）是一种**设计思想**，就是 **将原本在程序中手动创建对象的控制权，交由Spring框架来管理。** **IoC 容器是 Spring 用来实现 IoC 的载体，  IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。**

   IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。

   Spring 时代我们一般通过 XML 文件来配置 Bean，后来开发人员觉得 XML 文件来配置不太好，于是 SpringBoot 注解配置就慢慢开始流行起来。

   IoC初始化过程：

   ![Spring IoC的初始化过程](D:\面试\面试题\img\SpringIOC初始化过程.png)

2. 什么是AOP？

   AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，**却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来**，便于**减少系统的重复代码**，**降低模块间的耦合度**，并**有利于未来的可拓展性和可维护性**。

   **基于动态代理的**，如果要代理的对象，实现了某个接口，那么Spring AOP会使用**JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用**Cglib** ，这时候Spring AOP会使用 **Cglib** 生成一个被代理对象的子类来作为代理。
   
3. beanFactory和factoryBean的区别？

   **BeanFactory**定义了IOC容器的最基本形式，并提供了IOC容器应遵守的的最基本的接口，也就是Spring IOC所遵守的最底层和最基本的编程规范。在Spring代码中，BeanFactory只是个接口，并不是IOC容器的具体实现，但是Spring容器给出了很多种实现，如 DefaultListableBeanFactory、XmlBeanFactory、ApplicationContext等，都是附加了某种功能的实现。

   Spring通过反射机制利用<bean>的class属性指定实现类实例化Bean，在某些情况下，实例化Bean过程比较复杂，如果按照传统的方式，则需要在<bean>中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。Spring为此提供了一个org.springframework.bean.factory.FactoryBean的工厂类接口，用户可以通过实现该接口定制实例化Bean的逻辑。

   区别：
   BeanFactory是个Factory，也就是IOC容器或对象工厂，FactoryBean是个Bean。在Spring中，所有的Bean都是由BeanFactory(也就是IOC容器)来进行管理的。但对FactoryBean而言，这个Bean不是简单的Bean，而是一个能生产或者修饰对象生成的工厂Bean,它的实现与设计模式中的工厂模式和修饰器模式类似。

4. bean的作用域？

   - singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。

   - prototype : 每次请求都会创建一个新的 bean 实例。

   - request : 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。

   - session : 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。

5. bean的生命周期？

   ![Spring Bean 生命周期](D:\面试\面试题\img\bean生命周期.jpg)

6. 单例bean是否线程安全？

   的确是存在安全问题的。因为，当多个线程操作同一个对象的时候，对这个对象的成员变量的写操作会存在线程安全问题。

   但是，一般情况下，我们常用的 `Controller`、`Service`、`Dao` 这些 Bean 是无状态的。无状态的 Bean 不能保存数据，因此是线程安全的。

   常见的有 2 种解决办法：

   1. 在类中定义一个 `ThreadLocal` 成员变量，将需要的可变成员变量保存在  `ThreadLocal`  中（推荐的一种方式）。
   2. 改变 Bean 的作用域为 “prototype”：每次请求都会创建一个新的 bean 实例，自然不会存在线程安全问题。

7. springMVC的原理？

   1. 客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
   2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
   3. 解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
   4. `HandlerAdapter` 会根据 `Handler `来调用真正的处理器来处理请求，并处理相应的业务逻辑。
   5. 处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
   6. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
   7. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
   8. 把 `View` 返回给请求者（浏览器）

8. spring框架用到了哪些设计模式？

   - **工厂设计模式** : Spring使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。

   - **代理设计模式** : Spring AOP 功能的实现。

   - **单例设计模式** : Spring 中的 Bean 默认都是单例的。

     ```java
     public class Singleton {
     	private volatile static Singleton instance = null;
     	// 私有化构造方法
     	private Singleton() {
      
     	}
     	public static Singleton getInstance() {
     		if (instance == null) {
     			synchronized (Singleton.class) {
     				if (instance == null) {
     					instance = new Singleton();
     				}
     			}
     		}
     		return instance;
     	}
     }
     ```

     

   - **模板方法模式** : Spring 中 `jdbcTemplate`、`hibernateTemplate` 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。

   - **包装器设计模式** : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。

   - **观察者模式:** Spring 事件驱动模型就是观察者模式很经典的一个应用。

   - **适配器模式** :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配`Controller`。

9. spring管理事务的方式？

   1. 编程式事务，在代码中硬编码。(不推荐使用)
   2. 声明式事务，在配置文件中配置（推荐使用）

10. spring事务的隔离级别？

    - **DEFAULT:**  使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 
    - **READ_UNCOMMITTED:** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**
    - **READ_COMMITTED:**   允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**
    - **REPEATABLE_READ:**  对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生。**
    - **SERIALIZABLE:**   最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

11. spring事务的传播行为？

    事务传播行为用来描述由某一个事务传播行为修饰的方法被嵌套进另一个方法的时候事务如何传播。

    **注：这两个方法一定不能是同一个类中的，否则会失效**

    **支持当前事务的情况：**

    - **TransactionDefinition.PROPAGATION_REQUIRED：** 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。
    - **TransactionDefinition.PROPAGATION_SUPPORTS：** 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。
    - **TransactionDefinition.PROPAGATION_MANDATORY：** 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）

    **不支持当前事务的情况：**

    - **TransactionDefinition.PROPAGATION_REQUIRES_NEW：** 创建一个新的事务，如果当前存在事务，则把当前事务挂起。
    - **TransactionDefinition.PROPAGATION_NOT_SUPPORTED：** 以非事务方式运行，如果当前存在事务，则把当前事务挂起。
    - **TransactionDefinition.PROPAGATION_NEVER：** 以非事务方式运行，如果当前存在事务，则抛出异常。

    **其他情况：**

    - **TransactionDefinition.PROPAGATION_NESTED：** 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。

12. @Transactional作用在哪些地方？

    - 作用于类：该类的public方法都配置相同的事务属性信息。
    - 作用于方法：当类配置了@Transactional，方法也配置了@Transactional，方法的事务会覆盖类的事务配置信息。
    - 作用于接口：不推荐这种使用方法，因为一旦标注在Interface上并且Spring AOP 使用CGLib动态代理，将会导致@Transactional注解失效
    
13. @Transactional常用的参数？

    | 属性名      | 说明                                                         |
    | ----------- | ------------------------------------------------------------ |
    | propagation | 事务的传播行为，默认值为 REQUIRED，可选的值在上面介绍过      |
    | isolation   | 事务的隔离级别，默认值采用 DEFAULT，可选的值在上面介绍过     |
    | timeout     | 事务的超时时间，默认值为-1（不会超时）。如果超过该时间限制但事务还没有完成，则自动回滚事务。 |
    | readOnly    | 指定事务是否为只读事务，默认值为 false。                     |
    | rollbackFor | 用于指定能够触发事务回滚的异常类型，并且可以指定多个异常类型。 |

14.  @Transactional失效的场景？

    - @Transactional 应用在非 public 修饰的方法上

    - @Transactional 注解属性 propagation 设置错误

      这种失效是由于配置错误，若是错误的配置以下三种 propagation，事务将不会发生回滚。

      TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。

      TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。

      TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。

    - @Transactional 注解属性 rollbackFor 设置错误

      Spring默认抛出了未检查unchecked异常（继承自 RuntimeException 的异常）或者 Error才回滚事务；其他异常不会触发回滚事务。如果在事务中抛出其他类型的异常，但却期望 Spring 能够回滚事务，就需要指定 rollbackFor属性。

    - 同一个类中方法调用，导致@Transactional失效

      其实这还是由于使用Spring AOP代理造成的，因为只有当事务方法被当前类以外的代码调用时，才会由Spring生成的代理对象来管理。

    - 异常被你的 catch“吃了”导致@Transactional失效

    - 数据库引擎不支持事务，比如使用myisam引擎

15. springboot自动装配原理？

    简单来说，Spring Boot 通过`@EnableAutoConfiguration`开启自动装配，通过 SpringFactoriesLoader 最终加载`META-INF/spring.factories`中的自动配置类实现自动装配，自动配置类其实就是通过`@Conditional`按需加载的配置类，想要其生效必须引入`spring-boot-starter-xxx`包实现起步依赖
    
16. spring如何解决循环依赖问题？

    （1）什么是循环依赖？

    2个或以上bean 互相持有对方，最终形成闭环。

    （2）spring中循环依赖的场景？

    - 构造器的循环依赖。【这个Spring解决不了】
    - 【setter循环依赖】field属性的循环依赖【setter方式 单例，默认方式-->通过递归方法找出当前Bean所依赖的Bean，然后提前缓存【会放入Cach中】起来。通过提前暴露 -->暴露一个exposedObject用于返回提前暴露的Bean。】

    （3）如何检测循环依赖？

    可以 Bean在创建的时候给其打个标记，如果递归调用回来发现正在创建中的话--->即可说明循环依赖。

    （4）怎么解决？

    Spring为了解决单例的循环依赖问题，使用了**三级缓存**。

    这三级缓存分别指：

     singletonFactories ： 单例对象工厂的cache 
     earlySingletonObjects ：提前暴光的单例对象的Cache 。【用于检测循环引用，与singletonFactories互斥】
     singletonObjects：单例对象的cache
    
17. 过滤器和拦截器的区别？

    - 拦截器基于反射机制，而过滤器是基于函数回调

    - 拦截器不依赖servlet，而过滤器依赖于servlet只能在web程序中使用

    - 拦截器只能对action请求起作用，过滤器几乎可以对任意请求起作用

    - action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。

    - 拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。

    - 触发时机：

      <img src="https://images2017.cnblogs.com/blog/330611/201710/330611-20171023144517066-24770749.png" alt="img" style="zoom: 80%;" />

18. SpringSecurity？

    核心就是一组过滤器链，项目启动后将会自动配置。最核心的就是 Basic Authentication Filter 用来认证用户的身份，一个在spring security中一种过滤器处理一种认证方式。

19. SSO单点登录的原理？

    核心思路就是客户端保存登录通过的AuthToken，服务器端通过redis保存登录信息。客户端AuthToken保存在cookie中，可能涉及跨域问题，可以通过回调的方式，将token传给主域名之外的站点。

20. 数据脱敏？

    数据脱敏也叫数据的去隐私化，对手机号、身份证号等进行转换或者修改，比如用*表示

    - 静态数据脱敏

      适用于将数据抽取出生产环境脱敏分发至测试、开发、培训、数据分析等场景

    - 动态脱敏：用于生产环境

    - 数据脱敏方案：

      - 无效化，采用*代替
      - 随机值
      - 数据替换
      - 对称加密
      - 平均值
      - 偏移和取整

21. CAP理论？

    C一致性、A高可用、P分区容错性。P一定要满足，但是C和A只能满足一个。

    （1）为什么CA只能保证一个？

    因为为了保证C一致性，一个节点在写操作时，必须要禁止其他节点的读写操作，这就和A发生冲突了。

    （2）注册中心选择CP还是AP？

    zookeeper是CP；eureka是AP；nacos两种都支持，可以选择。

    对于服务注册来说，即使注册中心的不同节点保存的服务注册信息不同，也不会造成灾难性后果，能消费才是最重要的，**可用性比数据一致性更重要，选择AP**

    （3）分布式锁选择CP还是AP？

    数据库利用唯一索引进行上锁，但是mysql无法自动切换主从，基本无法实现P分区容错性，不再讨论范围。

    redis是AP，假设主服务器加锁，数据还没同步到从服务器，主服务器挂了，然后从服务器成为主服务器，就会有两个线程获得锁。redis适用于社交发帖等不需要强一致性的场景，而不适合交易类型。

    zookeeper实现分布式锁是CP。

    redis性能最高，zookeeper更加可靠，具体根据业务场景来选择分布式锁。

22. BASE模型

    BASE模型不同于传统事务ACID模型，强调牺牲高一致性，从而获得可用性，允许数据一段时间内不一致，只要保证最终一致性。

23. 什么是幂等性？

    **幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。**

24. 分布式事务？

    基于BASE理论，是最终一致性模型。

    （1）两阶段提交（2PC）

    分为预提交和提交两个阶段。业界很少使用，因为缺点很明显，就是同步阻塞问题：在资源准备就绪之后，资源管理器中的资源就一直处于阻塞，直到提交完成之后，才进行资源释放。开销大、效率低。

    （2）补偿事务（TCC）

    TCC是服务化的两阶段变成模型，每个业务服务都必须实现 try，confirm，calcel三个方法，这三个方式可以对应到SQL事务中Lock，Commit，Rollback。

    ![image](https://user-gold-cdn.xitu.io/2019/9/6/16d0588ab8cd2a20?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

    ![image](https://user-gold-cdn.xitu.io/2019/9/6/16d0588ab8c51652?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

    （3）本地消息表

    本地消息表这种实现方式应该是业界使用最多的，其核心思想是将分布式事务拆分成本地事务进行处理。也就是需要一个消息队列。![image](https://user-gold-cdn.xitu.io/2019/9/6/16d0588acde414a6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

    （4）消息事务

    RocketMQ很好的支持消息事务

    ![img](https://pic2.zhimg.com/80/v2-72ba7bed684e855606c44ddda185987d_720w.jpg)

    （5）最大努力通知

    **最大努力通知其实只是表明了一种柔性事务的思想**：我已经尽力我最大的努力想达成事务的最终一致了。本地消息表也可以算最大努力，事务消息也可以算最大努力。

#### 5.2 Netty

1. BIO、NIO、AIO的区别？

   - **BIO (Blocking I/O):**  同步阻塞 I/O 模式，数据的读取写入必须阻塞在一个线程内等待其完成。在客户端连接数量不高的情况下，是没问题的。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。
   - **NIO (Non-blocking/New I/O):** NIO 是一种同步非阻塞的 I/O 模型，于 Java 1.4 中引入，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为  Non-blocking，不单纯是 New。它支持面向缓冲的，基于通道的 I/O 操作方法。 NIO 提供了与传统 BIO 模型中的 `Socket` 和 `ServerSocket` 相对应的 `SocketChannel` 和 `ServerSocketChannel` 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发
   - **AIO (Asynchronous I/O):** AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的 IO 模型。异步 IO  是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步 IO 的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在  IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO 操作本身是同步的。

2. 什么是netty？

   1. Netty 是一个 **基于 NIO** 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。
   2. 它极大地简化并优化了 TCP 和 UDP 套接字服务器等网络编程,并且性能以及安全性等很多方面甚至都要更好。
   3. **支持多种协议** 如 FTP，SMTP，HTTP 以及各种二进制和基于文本的传统协议。

3. 为什么不直接用NIO？为什么用netty？

   NIO的编程模型复杂而且存在一些BUG，并且对编程功底要求比较高。

   netty优点：

   - 统一的 API，支持多种传输类型，阻塞和非阻塞的。

   - 简单而强大的线程模型。

   - 自带编解码器解决 TCP 粘包/拆包问题。

   - 自带各种协议栈。

   -  真正的无连接数据包套接字支持。

   - 比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。

   - 安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。

4. netty核心组件？

   （1）Channel

   Channel 接口是 Netty 对网络操作抽象类，它除了包括基本的 I/O 操作，如 bind()、connect()、read()、write() 等。

   比较常用的Channel接口实现类是NioServerSocketChannel（服务端）和NioSocketChannel（客户端），这两个 Channel 可以和 BIO 编程模型中的ServerSocket以及Socket两个概念对应上。Netty 的 Channel  接口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。

   （2）EventLoop

   EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。

   （3）ChannelFuture

   Netty 是异步非阻塞的，所有的 I/O 操作都为异步的。

   因此，我们不能立刻得到操作是否执行成功，但是，你可以通过 ChannelFuture 接口的 addListener() 方法注册一个 ChannelFutureListener，当操作执行成功或者失败时，监听就会自动触发返回结果。

   我们还可以通过 ChannelFuture 接口的 sync()方法让异步的操作变成同步的。

   （4）ChannelHandler 和 ChannelPipeline

   ChannelHandler 是消息的具体处理器。他负责处理读写操作、客户端连接等事情。

   ChannelPipeline 为 ChannelHandler 的链，提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API 。当 Channel 被创建时，它会被自动地分配到它专属的 ChannelPipeline。

   我们可以在 ChannelPipeline 上通过 addLast() 方法添加一个或者多个ChannelHandler  ，因为一个数据或者事件可能会被多个 Handler 处理。当一个 ChannelHandler 处理完之后就将数据交给下一个  ChannelHandler 。

5. EventloopGroup 了解么?和 EventLoop 啥关系?

   EventLoopGroup 包含多个 EventLoop（每一个 EventLoop 通常内部包含一个线程）

6. Bootstrap 和 ServerBootstrap 了解么？

   Bootstrap 是客户端的启动引导类/辅助类，ServerBootstrap 服务端的启动引导类/辅助类。

   Bootstrap 通常使用 connet() 方法连接到远程的主机和端口，作为一个 Netty TCP 协议通信中的客户端。另外，Bootstrap 也可以通过 bind() 方法绑定本地的一个端口，作为 UDP 协议通信中的一端。ServerBootstrap通常使用 bind() 方法绑定本地的端口上，然后等待客户端的连接。Bootstrap 只需要配置一个线程组— EventLoopGroup ,而 ServerBootstrap需要配置两个线程组— EventLoopGroup ，一个用于接收连接，一个用于具体的处理。

7. NioEventLoopGroup 默认的构造函数会起多少线程？

   我们发现 NioEventLoopGroup 默认的构造函数实际会起的线程数为 CPU核心数*2。

8. Netty的线程模型？

   Reactor 模式基于事件驱动，采用多路复用将事件分发给相应的 Handler 处理，非常适合处理海量 IO 的场景。

   在 Netty 主要靠 NioEventLoopGroup 线程池来实现具体的线程模型的 。

   我们实现服务端的时候，一般会初始化两个线程组：

   bossGroup :接收连接。workerGroup ：负责具体的处理，交由对应的 Handler 处理。

   （1）单线程模型

   一个线程需要执行处理所有的 accept、read、decode、process、encode、send 事件。对于高负载、高并发，并且对性能要求比较高的场景不适用。

   （2）多线程模型

   一个 Acceptor 线程只负责监听客户端的连接，一个 NIO  线程池负责具体处理：accept、read、decode、process、encode、send  事件。满足绝大部分应用场景，并发连接量不大的时候没啥问题，但是遇到并发连接大的时候就可能会出现问题，成为性能瓶颈。

   （3）主从多线程模型

   从一个 主线程 NIO 线程池中选择一个线程作为 Acceptor  线程，绑定监听端口，接收客户端连接的连接，其他线程负责后续的接入认证等工作。连接建立完成后，Sub NIO 线程池负责具体处理 I/O  读写。如果多线程模型无法满足你的需求的时候，可以考虑使用主从多线程模型 。

9. netty零拷贝？

   Netty 中的零拷贝体现在以下几个方面：

   使用 Netty 提供的 CompositeByteBuf 类, 可以将多个ByteBuf 合并为一个逻辑上的 ByteBuf, 避免了各个 ByteBuf 之间的拷贝。ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf, 避免了内存的拷贝。通过 FileRegion 包装的FileChannel.tranferTo 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel, 避免了传统通过循环 write 方式导致的内存拷贝问题。

10. select、poll和epoll的区别？

    （1）select

    - select单个进程可监视的fd（文件描述符）数量被限制，32位只有1024个，64位只有2048个。
    - 对socket的进行线性扫描，即轮询的方法，效率较低o(n)
    - 消息传递，用户传递的数组拷贝到内核空间，复制开销大。

    （2）poll

    - 和select本质上没有什么区别，没有最大连接数的限制，因为它是用链表存储的
    - poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

    （3）epoll

    - **没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）**；
    - **效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；**即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。
    - 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。
    
11. select、poll和epoll详解

    **前置知识：**

    - socket有三个区域：写缓冲区、读缓冲区、等待队列（存放需要等待该socket的进程）
    - 中断：如何知道接受了数据，当网卡接收到数据时，会向CPU发出中断指令进行中断进程，主要实现两件事，第一将数据复制到内存中，第二唤醒socket对应的进程

    （1）select

    ```c
    int select(int maxfdp1,fd_set *readset,fd_set *writeset,fd_set *exceptset,const struct timeval *timeout);
    ```

    select使用的主要数据结构fd_set，本质上是一个1024位的bitmap，然后用一个uLong数组表示这个bitmap。

    其一，每次调用select都需要将进程加入到所有监视socket的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个fds列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定select的最大监视数量，默认只能监视1024个socket。

    其二，进程被唤醒后，程序并不知道哪些socket收到数据，还需要遍历一次。

    （2）poll

    ```c
    int poll(struct pollfd *fds, nfds_t nfds, int timeout);
    
    typedef struct pollfd {
            int fd;                         // 需要被检测或选择的文件描述符
            short events;                   // 对文件描述符fd上感兴趣的事件
            short revents;                  // 文件描述符fd上当前实际发生的事件
    } pollfd_t;
    ```

    和select基本没有什么区别，主要是使用了pollfd数组，不在有文件描述符数量限制。

    （3）epoll

    ```c
    int epoll_create(int size);
    int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
    int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
    ```

    主要是三个函数

    - 调用epoll_create时，内核除了帮我们在epoll文件系统里建了个eventpoll结点epfd，在内核cache里建了个**红黑树**用于存储以后epoll_ctl传来的socket外，还会再建立一个**rdllist双向链表**，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个rdllist双向链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。

      所有添加到epoll中的事件都会与设备(如网卡)驱动程序**建立回调关系**，也就是说相应事件的发生时会调用这里的回调方法。这个回调方法在内核中叫做**ep_poll_callback**，它会把这样的事件放到上面的rdllist双向链表中。

    - 当调用epoll_wait检查是否有发生事件的连接时，只是检查eventpoll对象中的rdllist双向链表是否有epitem元素而已，如果rdllist链表不为空，则这里的事件复制到用户态内存（使用共享内存提高效率）中，同时将事件数量返回给用户。因此epoll_waitx效率非常高。epoll_ctl在向epoll对象中添加、修改、删除事件时，从rbr红黑树中查找事件也非常快，也就是说epoll是非常高效的，它可以轻易地处理百万级别的并发连接。

    两种触发模式：

    - LT（水平触发）模式下，只**要这个文件描述符还有数据可读，每次 epoll_wait都会返回它的事件**，提醒用户程序去操作；
    - ET模式（边缘触发）**只有数据到来才触发**，**不管缓存区中是否还有数据**，缓冲区剩余未读尽的数据不会导致epoll_wait返回；

#### 5.3 zookeeper

1. 分布式锁

   （1）基于数据库

   对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功。

   缺点：

   ​	1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。
   ​	2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。
   ​	3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。
   ​	4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。

   解决方案：
        1、数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。
        2、没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。
        3、非阻塞的？搞一个while循环，直到insert成功再返回成功。
        4、非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。

   （2）基于redis缓存实现

   redis中使用分布式锁很简单，只要使用setnx指令对某个key上锁就行：

   setnx lock test //上锁del lock test   //解锁当某个key没有被占用的时候，setnx指令会返回1，否则返回0，这就是Redis中分布式锁的使用原理。

   当然我们还可以在上锁之后使用expire指令给锁设置过期时间。

   缺点：

   在这种场景（主从结构）中存在明显的竞态:
       客户端A从master获取到锁，
       在master将锁同步到slave之前，master宕掉了。
       slave节点被晋级为master节点，
       客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。安全失效！

   （3）基于zookeeper实现

   Zookeeper分布式锁恰恰应用了临时顺序节点。

   **获取锁**

   首先，在Zookeeper当中创建一个持久节点ParentLock。当第一个客户端想要获得锁时，需要在ParentLock这个节点下面创建一个**临时顺序节点** Lock1。

   之后，Client1查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock1是不是顺序最靠前的一个。如果是第一个节点，则成功获得锁。

   这时候，如果再有一个客户端 Client2 前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock2。

   Client2查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock2是不是顺序最靠前的一个，结果发现节点Lock2并不是最小的。

   于是，Client2向排序仅比它靠前的节点Lock1注册Watcher，用于监听Lock1节点是否存在。这意味着Client2抢锁失败，进入了等待状态。

   这时候，如果又有一个客户端Client3前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock3。

   Client3查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock3是不是顺序最靠前的一个，结果同样发现节点Lock3并不是最小的。

   于是，Client3向排序仅比它靠前的节点Lock2注册Watcher，用于监听Lock2节点是否存在。这意味着Client3同样抢锁失败，进入了等待状态。

   这样一来，Client1得到了锁，Client2监听了Lock1，Client3监听了Lock2。这恰恰形成了一个等待队列，很像是Java当中ReentrantLock所依赖的

   **释放锁**

   释放锁分为两种情况：

   **1.任务完成，客户端显示释放**

   当任务完成时，Client1会显示调用删除节点Lock1的指令。

   **2.任务执行过程中，客户端崩溃**

   获得锁的Client1在任务执行过程中，如果Duang的一声崩溃，则会断开与Zookeeper服务端的链接。根据临时节点的特性，相关联的节点Lock1会随之自动删除。

   由于Client2一直监听着Lock1的存在状态，当Lock1节点被删除，Client2会立刻收到通知。这时候Client2会再次查询ParentLock下面的所有节点，确认自己创建的节点Lock2是不是目前最小的节点。如果是最小，则Client2顺理成章获得了锁。

   **缺点：**

     性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。

#### 5.4 ElasticSearch

1. ES的功能？适用场景？

   **功能：**

   （1）分布式的搜索引擎和数据分析引擎

   （2）全文检索，结构化检索，数据分析

   （3）对海量数据进行近实时的处理

   场景：

   - 全文搜索、高亮、搜索推荐
   - 电商网站，商品模糊搜索
   - 日志数据分析

2. ES名词概念？

   - 集群 Cluster：由一个或多个节点组成，对外提供服务。
   - 节点 Node：一个 Elasticsearch的运行实例，是集群的构成单元。
   - 索引 Index：由具有相同字段的文档列表组成。相当于mysql中的database，一个集群可以有多个索引，如nginx按天nginx-log-2020-05-01建索引。
   - 类型 Type：ES6.5以后已经不使用type了。统一为_doc。相当于mysql中的table。
   - 文档 Document：用户存储在 es 中的数据文档。相当于mysql中的row（一行数据）。
   - 映射 Mapping：文档结构描述。分静态映射（事先定义字段的数据类型、分词器等属性）和动态映射（根据写入的字段进行类型推测）。
   - 分片 Shard：一个文档默认5个分片。相当于一桶水用了N个杯子装。主分片和备分片不会出现在同一个节点上（防止单点故障）
   - 段 Segment：每个分片包含多个segment，每一个segment都是一个倒排索引；在查询会把所有的segment查询结果汇总归并后作为最终的分片查询结果,然后返回。
   - 倒排索引 Search：基于luence。
   - 分词 Term：Mapping定义中的分词定义字段

3. ES倒排索引？

   倒排索引是搜索引擎到核心，主要包括两部分：

   - 单词词典（Term Dictionary）   
     - 记录所有文档的单词，一般都比较大
     - 记录单词到倒排列表的关联信息（文档ID）
   - 倒排列表（Posting List）：   
     - 记录了单词对应的文档集合，由倒排索引项（Posting）组成

   单词词典的实现一般是 B+ Tree;

   倒排索引项（Posting）主要包含如下信息：
   
   - 文档Id，用于获取原始信息
   - 单词频率（TF, Term Frequency），记录该单词在该文档中的出现次数，用于后续相关性算法
   - 位置（Position），记录单词在文档中的分词位置（多个），用于做词语搜索（Phrase Query）
   - 偏移（Offset），记录单词在文档的开始和结束位置，用于做高亮显示
   
   ![img](D:\面试\面试题\img\ES倒排索引.png)

#### 5.5 Mybatis

1. 什么是sql注入？Mybatis怎么防止sql注入？

   **sql注入**：

   简而言之，是在输入的字符串之中注入SQL指令，在设计不良的程序当中忽略了检查，那么这些注入进去的指令就会被数据库服务器误认为是正常的SQL指令而运行，因此遭到破坏或是入侵。常见的就是sql拼接，造成恶意修改原本sql的方法。

   **mybatis 解决 SQL 注入问题：**

   我们使用 mybatis 编写 SQL 语句时，难免会使用模糊查询的方法，mybatis 提供了两种方式 `#{}` 和 `${}` 。

   - `#{value}` 在预处理时，会把参数部分用一个占位符 ? 替代，其中 value 表示接受输入参数的名称。能有效解决 SQL 注入问题
   - `${}` 表示使用拼接字符串，将接受到参数的内容不加任何修饰符拼接在 SQL 中，使用`${}`拼接 sql，将引起 SQL 注入问题。

   【底层实现原理】MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。
   
2. 通常一个mapper.xml文件，都会对应一个Dao接口，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？

   Mapper 接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，根据类的全限定名+方法名，唯一定位到一个MapperStatement并调用执行器执行所代表的sql，然后将sql执行结果返回。

   Mapper接口里的方法，是不能重载的，因为是使用 全限名+方法名 的保存和寻找策略。

#### 5.6 Nginx

1. 了解Nginx服务器吗？有哪些优点？适用场景？

   Nginx 是一个高性能的 Web 和反向代理服务器

   优点：

   - 支持高并发连接。因为底层使用的是epoll网络IO
   - 内存消耗少
   - 成本低
   - 配置文件简单
   - 支持Rewrite重写
   - 节省带宽
   - 稳定性高
   - 支持热部署

   常见的使用场景：

   - 静态资源服务器
   - 反向代理服务器
   - 统一访问入口
   - 负载均衡
   - 解决跨域问题
   - 行为分析

2. Nginx工作原理？

   - nginx在启动后，会有一个master进程和多个worker进程。master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。
   - 而基本的网络事件，则是放在worker进程中来处理了。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。
   - 一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。

#### 5.7 RabbitMQ

1. 消息队列使用场景？

   消息队列中间件是分布式系统中重要的组件，主要解决**应用解耦，异步消息，流量削锋**等问题，实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ。

   **场景**：异步处理、应用解耦、流量削峰、日志处理、消息通讯、发布/订阅等。

### 6. 工具

#### 6.1 GIT

1. git常用命令？

   git add readme.md

   git commit -m "xxx"

   git push origin master

   git remote -v

   git clone

   git remote origin git@xxx.com

#### 6.2 Docker

1. docker常用命令？



   

